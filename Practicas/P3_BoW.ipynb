{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 3. Bolsas de palabras\n",
    "Guillermo Segura Gómez\n",
    "\n",
    "## MEX-A3T: Aggressiveness Analysis\n",
    "\n",
    "Vamos a utilizar un corpus llamado [MEX-A3T](https://sites.google.com/view/mex-a3t/home?authuser=0) que es un corpus creado en México. MEX-A3T es un corpus hecho para poder medir la agresividad y las fake news. El equipo de CIMAT se dedicó al análisis de identificación de agresividad. \n",
    "\n",
    "Lo primero que es necesario hacer es leer los datos del corpus. El corpus incluye datos de entrenamiento asi como etiquetas.\n",
    "\n",
    "**Keras**\n",
    "\n",
    "Se introduce la libería **keras**. Keras es una biblioteca de Redes Neuronales de Código Abierto escrita en Python. Es capaz de ejecutarse sobre TensorFlow, Microsoft Cognitive Toolkit o Theano.\n",
    "\n",
    "Está especialmente diseñada para posibilitar la experimentación en más o menos poco tiempo con redes de Aprendizaje Profundo. Sus fuertes se centran en ser amigable para el usuario, modular y extensible.\n",
    "\n",
    "**Tensorflow**\n",
    "\n",
    "Además trabajaremos con la libería **tensorflow**. TensorFlow es una biblioteca de código abierto para aprendizaje automático a través de un rango de tareas, y desarrollado por Google para satisfacer sus necesidades de sistemas capaces de construir y entrenar redes neuronales para detectar y descifrar patrones y correlaciones, análogos al aprendizaje y razonamiento usados por los humanos.\n",
    "\n",
    "**¿Qué es un tokenizador?**\n",
    "\n",
    "Recordando el concepto de tokenizador que realizamos en la práctica 2. Un tokenizador es una herramienta que se utiliza para dividir un texto en unidades más pequeñas llamadas tokens. Estos tokens suelen ser palabras, pero también pueden ser caracteres o subpalabras, dependiendo de cómo se configure el tokenizador. El proceso de tokenización es un paso fundamental en muchas tareas de NLP, ya que permite convertir texto no estructurado en una forma que los modelos de machine learning pueden entender y procesar.\n",
    "\n",
    "Por ejemplo, la frase \"Me gusta programar en Python\" podría tokenizarse en los tokens [\"Me\", \"gusta\", \"programar\", \"en\", \"Python\"].\n",
    "\n",
    "**Tokenizador de Keras**\n",
    "\n",
    "El tokenizador `from keras.preprocessing.text import Tokenizer`, es una herramienta que viene con Keras. Este tokenizador realiza precisamente la tarea descrita anteriormente: divide el texto en tokens y puede convertir estos tokens en secuencias de números, lo que los hace útiles para entrenar modelos de deep learning.\n",
    "\n",
    "Sin embargo, este componente ahora forma parte de TensorFlow, bajo `tf.keras.preprocessing.text.Tokenizer`. Desde que TensorFlow absorbió Keras como su API de alto nivel, la mayoría de las herramientas de Keras se acceden a través del módulo `tf.keras`.\n",
    "\n",
    "**Tokenizador de TensorFlow**\n",
    "\n",
    "El tokenizador que encontraste en TensorFlow (`tf.keras.preprocessing.text.Tokenizer`) funciona de manera muy similar al tokenizador original de Keras. Aquí tienes una descripción de los parámetros que mencionaste:\n",
    "\n",
    "- `num_words`: El número máximo de palabras que se guardarán, basado en la frecuencia de palabra. Solo las `num_words` más comunes serán retenidas.\n",
    "- `filters`: Una cadena en la que cada elemento es un carácter que se filtrará del texto. Es decir, estos caracteres serán ignorados durante la tokenización.\n",
    "- `lower`: Un booleano que indica si se debe convertir el texto a minúsculas.\n",
    "- `split`: El carácter que se utilizará como delimitador para dividir el texto en tokens.\n",
    "- `char_level`: Si es True, cada carácter será tratado como un token.\n",
    "- `oov_token`: Un valor que se asignará a los tokens fuera del vocabulario (palabras que no se han visto durante el entrenamiento).\n",
    "- `analyzer`: Este parámetro no está documentado en la versión estándar de TensorFlow y podría no ser aplicable.\n",
    "\n",
    "Para utilizar este tokenizador, primero instancias el objeto `Tokenizer` con los parámetros que desees y luego lo ajustas a tus textos utilizando el método `.fit_on_texts(texts)`. Después de ajustarlo, puedes usar `.texts_to_sequences(texts)` para convertir tus textos en secuencias de números, que son los índices de los tokens en el vocabulario del tokenizador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 3, 4, 5, 1], [1, 6, 7, 8, 9, 10]]\n"
     ]
    }
   ],
   "source": [
    "# Instanciando el tokenizador\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=1000)\n",
    "\n",
    "# Ejemplo de texto\n",
    "texts = [\"Me gusta programar en Python\", \"Python es genial para machine learning\"]\n",
    "\n",
    "# Ajustando el tokenizador en los textos\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "# Convirtiendo textos a secuencias de tokens\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "print(sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora trabajaremos con los archivos del corpus MEX-A3T, necesitamos una función que lea los archivos del corpus y nos regrese el texto en una lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_file(path_corpus, path_truth):\n",
    "\n",
    "    tr_text = []\n",
    "    tr_labels = []\n",
    "\n",
    "    with open(path_corpus, \"r\") as f_corpus, open(path_truth, \"r\") as f_truth:\n",
    "        for tweet in f_corpus:\n",
    "            tr_text += [tweet]\n",
    "        for label in f_truth:\n",
    "            tr_labels += [label]\n",
    "\n",
    "    return tr_text, tr_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_text = \"/Users/guillermo_sego/Desktop/Segundo Semestre/PLN/MexData/mex20_train.txt\"\n",
    "path_labels = \"/Users/guillermo_sego/Desktop/Segundo Semestre/PLN/MexData/mex20_train_labels.txt\"\n",
    "\n",
    "tr_text, tr_labels = get_text_from_file(path_text, path_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@USUARIO @USUARIO @USUARIO Q se puede esperar del maricon de closet de la Yañez aun recuerdo esa ves q lo vi en zona rosa viendo quien lo levantada\\n',\n",
       " '@USUARIO La piel nueva siempre arde un poquito los primeros días... y más con este puto clima\\n',\n",
       " 'Ustedes no se enamoran de mí… por tontas.\\n',\n",
       " 'Me las va a pagar esa puta gorda roba tuits...\\n',\n",
       " '@USUARIO LA GENTE ES TONTA PORQUE NO SE DAN CUENTA QUE TÚ HACES A BATMAN AZUL\\n']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1\\n', '0\\n', '1\\n', '1\\n', '0\\n']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_labels[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El contenido de los arreglos es la información encontrada en el corpus de entrenamiento. En el arreglo **tr_text** encontramos el texto de los tweets, mientras que en el arreglo **tr_labels** está la etiqueta de si es agresivo o no es agresivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estadísticas Simples\n",
    "\n",
    "Vamos a realizar una inspección de los datos, esto con el propósito de observar cuantos datos hay. Podemos utilizar la libería matplotlib para este fin. Además utilizamos un contador de la librería counter. Vamos a contar las etiquetas del data set y construimos un histograma. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'0\\n': 3759, '1\\n': 1519})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Class')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "print(Counter(tr_labels))\n",
    "\n",
    "plt.hist(tr_labels, bins=len(set(tr_labels)))\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.xlabel(\"Class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay mas contenido que no es agresivo, mas del doble.\n",
    "\n",
    "## Construcción del vocabulario\n",
    "\n",
    "Ahora vamos a constuir el vocabulario utilizando el método de **TweetTokenizer** de la clase *tokenize* de la librería nltk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tokenizer = TweetTokenizer() # Inicializar tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_palabras = []\n",
    "\n",
    "for doc in tr_text:\n",
    "    corpus_palabras += tokenizer.tokenize(doc)\n",
    "\n",
    "fdist = nltk.FreqDist(corpus_palabras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El tamaño del corpus es: 97473\n",
      "El tamaño del vocabulario es: 15194\n"
     ]
    }
   ],
   "source": [
    "print(f\"El tamaño del corpus es:\", len(corpus_palabras))\n",
    "print(f\"El tamaño del vocabulario es:\", len(fdist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@USUARIO',\n",
       " '@USUARIO',\n",
       " '@USUARIO',\n",
       " 'Q',\n",
       " 'se',\n",
       " 'puede',\n",
       " 'esperar',\n",
       " 'del',\n",
       " 'maricon',\n",
       " 'de']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_palabras[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({',': 3016, 'de': 2915, 'que': 2829, '.': 2604, 'la': 2031, 'a': 1956, 'y': 1856, '!': 1435, 'no': 1430, '@USUARIO': 1399, ...})"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La construcción de la bolsa de palabras en esta práctica se realiza a mano. Existen algunas librerias de Machine Learning que realizan este proceso, sin embargo no permiten determinar el total de información, ya que se pierden algunos detalles en el procesamiento.\n",
    "\n",
    "Ahora necesitamos ordenar las frecuencias del vocabulario para poder trabajar con el."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  SortFrecuency(freqdist):\n",
    "    # List comprenhension\n",
    "    aux = [(freqdist[key], key) for key in freqdist]\n",
    "    aux.sort() # Ordena la lista\n",
    "    aux.reverse() # Cambiar el orden\n",
    "\n",
    "    return aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3016, ','), (2915, 'de'), (2829, 'que'), (2604, '.'), (2031, 'la')]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc = SortFrecuency(fdist)\n",
    "voc = voc[:5000]\n",
    "voc[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a trabajar únicamente con los 5 mil términos mas comunes. Esto por simplicidad. Vamos a trabajar con un diccionario de python. Es bastante útil si podemos lograr tener la {palabra, valor} en donde el valor se refiere al índice de palabra o el lugar donde se encuentra, siendo 1 la palabra mas frecuente y 5000 la palabra menos frecuente, es decir estamos creando un diccionario que accesa a la palabra en función de su lugar en el vector. Además el diccionario tiene un orden de acceso bástante rápido ya que es una tabla hash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{',': 0,\n",
       " 'de': 1,\n",
       " 'que': 2,\n",
       " '.': 3,\n",
       " 'la': 4,\n",
       " 'a': 5,\n",
       " 'y': 6,\n",
       " '!': 7,\n",
       " 'no': 8,\n",
       " '@USUARIO': 9,\n",
       " 'me': 10,\n",
       " 'el': 11,\n",
       " 'en': 12,\n",
       " 'se': 13,\n",
       " 'es': 14,\n",
       " 'con': 15,\n",
       " '?': 16,\n",
       " 'verga': 17,\n",
       " 'los': 18,\n",
       " 'madre': 19,\n",
       " 'por': 20,\n",
       " 'las': 21,\n",
       " '\"': 22,\n",
       " 'un': 23,\n",
       " 'te': 24,\n",
       " 'mi': 25,\n",
       " 'lo': 26,\n",
       " 'putas': 27,\n",
       " 'una': 28,\n",
       " '...': 29,\n",
       " 'putos': 30,\n",
       " 'para': 31,\n",
       " '😂': 32,\n",
       " 'si': 33,\n",
       " 'ya': 34,\n",
       " 'como': 35,\n",
       " 'su': 36,\n",
       " 'pero': 37,\n",
       " 'tu': 38,\n",
       " 'loca': 39,\n",
       " 'le': 40,\n",
       " 'más': 41,\n",
       " 'No': 42,\n",
       " 'del': 43,\n",
       " 'gorda': 44,\n",
       " 'al': 45,\n",
       " 'bien': 46,\n",
       " 'A': 47,\n",
       " '¿': 48,\n",
       " 'Y': 49,\n",
       " 'son': 50,\n",
       " 'Me': 51,\n",
       " 'o': 52,\n",
       " 'feas': 53,\n",
       " 'cuando': 54,\n",
       " 'Que': 55,\n",
       " ':': 56,\n",
       " 'yo': 57,\n",
       " 'les': 58,\n",
       " 'porque': 59,\n",
       " 'ni': 60,\n",
       " 'está': 61,\n",
       " 'ser': 62,\n",
       " 'estoy': 63,\n",
       " 'sus': 64,\n",
       " 'todos': 65,\n",
       " 'esta': 66,\n",
       " 'puta': 67,\n",
       " 'Ya': 68,\n",
       " 'todo': 69,\n",
       " 'pinche': 70,\n",
       " 'puto': 71,\n",
       " 'tan': 72,\n",
       " 'Si': 73,\n",
       " 'La': 74,\n",
       " 'qué': 75,\n",
       " '…': 76,\n",
       " 'eso': 77,\n",
       " 'muy': 78,\n",
       " 'soy': 79,\n",
       " 'hasta': 80,\n",
       " 'así': 81,\n",
       " '¡': 82,\n",
       " '<URL>': 83,\n",
       " 'mamar': 84,\n",
       " 'hay': 85,\n",
       " 'q': 86,\n",
       " 'DE': 87,\n",
       " 'mis': 88,\n",
       " 'joto': 89,\n",
       " 'hace': 90,\n",
       " 'este': 91,\n",
       " 'cosas': 92,\n",
       " '️': 93,\n",
       " 'vida': 94,\n",
       " 'nos': 95,\n",
       " 'ver': 96,\n",
       " 'mejor': 97,\n",
       " 'solo': 98,\n",
       " 'nada': 99,\n",
       " 'vale': 100,\n",
       " 'va': 101,\n",
       " 'quiero': 102,\n",
       " 'marica': 103,\n",
       " 'eres': 104,\n",
       " 'día': 105,\n",
       " 'siempre': 106,\n",
       " 'esa': 107,\n",
       " 'voy': 108,\n",
       " 'gente': 109,\n",
       " 'Yo': 110,\n",
       " '😭': 111,\n",
       " 'vez': 112,\n",
       " 'El': 113,\n",
       " 'mierda': 114,\n",
       " '-': 115,\n",
       " 'tengo': 116,\n",
       " '(': 117,\n",
       " 'sin': 118,\n",
       " 'ese': 119,\n",
       " ')': 120,\n",
       " 'Es': 121,\n",
       " 'luchona': 122,\n",
       " '😍': 123,\n",
       " 'hdp': 124,\n",
       " 'ahora': 125,\n",
       " 'Por': 126,\n",
       " '😡': 127,\n",
       " '“': 128,\n",
       " 'tienen': 129,\n",
       " 'tiene': 130,\n",
       " 'pinches': 131,\n",
       " 'hacer': 132,\n",
       " 'tus': 133,\n",
       " 'tontas': 134,\n",
       " 'LA': 135,\n",
       " '”': 136,\n",
       " 'gusta': 137,\n",
       " 'Como': 138,\n",
       " 'sea': 139,\n",
       " 'HDP': 140,\n",
       " 'toda': 141,\n",
       " 'Se': 142,\n",
       " 'hoy': 143,\n",
       " 'Qué': 144,\n",
       " 'mamando': 145,\n",
       " 'están': 146,\n",
       " 'cagado': 147,\n",
       " 'tonta': 148,\n",
       " 'Pero': 149,\n",
       " 'puedo': 150,\n",
       " 'mas': 151,\n",
       " '🙄': 152,\n",
       " 'pendejo': 153,\n",
       " 'hijo': 154,\n",
       " 'NO': 155,\n",
       " 'En': 156,\n",
       " 'Mi': 157,\n",
       " 'mal': 158,\n",
       " 'estar': 159,\n",
       " 'QUE': 160,\n",
       " '..': 161,\n",
       " 'Lo': 162,\n",
       " 'algo': 163,\n",
       " 'PUTOS': 164,\n",
       " 'tener': 165,\n",
       " 'alguien': 166,\n",
       " 'Putos': 167,\n",
       " 'verdad': 168,\n",
       " 'mujer': 169,\n",
       " 'cabrona': 170,\n",
       " 'también': 171,\n",
       " 'da': 172,\n",
       " 'puede': 173,\n",
       " 'decir': 174,\n",
       " 'madres': 175,\n",
       " 'mujeres': 176,\n",
       " 'maricon': 177,\n",
       " 'vas': 178,\n",
       " 'mucho': 179,\n",
       " 'dos': 180,\n",
       " 'MADRE': 181,\n",
       " '❤': 182,\n",
       " 'van': 183,\n",
       " 'sé': 184,\n",
       " 'Estoy': 185,\n",
       " 'Cuando': 186,\n",
       " ';': 187,\n",
       " 'sí': 188,\n",
       " 'otra': 189,\n",
       " 'estás': 190,\n",
       " 'años': 191,\n",
       " 'Verga': 192,\n",
       " 'PUTAS': 193,\n",
       " 'Las': 194,\n",
       " 'ir': 195,\n",
       " 'chingada': 196,\n",
       " \"'\": 197,\n",
       " 'veces': 198,\n",
       " 'tú': 199,\n",
       " 'hijos': 200,\n",
       " 'De': 201,\n",
       " 'quiere': 202,\n",
       " 'quien': 203,\n",
       " 'pues': 204,\n",
       " 'jajaja': 205,\n",
       " 'VERGA': 206,\n",
       " 'Te': 207,\n",
       " '3': 208,\n",
       " 'mundo': 209,\n",
       " 'menos': 210,\n",
       " '2': 211,\n",
       " '🤔': 212,\n",
       " 'uno': 213,\n",
       " 'nunca': 214,\n",
       " 'era': 215,\n",
       " 'cada': 216,\n",
       " 'días': 217,\n",
       " 'dice': 218,\n",
       " 'México': 219,\n",
       " 'todas': 220,\n",
       " 'esos': 221,\n",
       " 'amor': 222,\n",
       " 'Una': 223,\n",
       " 'tanto': 224,\n",
       " 'mamá': 225,\n",
       " 'ganas': 226,\n",
       " 'esas': 227,\n",
       " 'O': 228,\n",
       " '😒': 229,\n",
       " 'tienes': 230,\n",
       " 'tiempo': 231,\n",
       " 'fue': 232,\n",
       " 'cuenta': 233,\n",
       " 'ME': 234,\n",
       " 'Jajajaja': 235,\n",
       " 'pendeja': 236,\n",
       " 'estaba': 237,\n",
       " 'dicen': 238,\n",
       " 'Madre': 239,\n",
       " 'wey': 240,\n",
       " 'pedo': 241,\n",
       " 'neta': 242,\n",
       " 'esto': 243,\n",
       " 'ti': 244,\n",
       " 'siento': 245,\n",
       " 'mañana': 246,\n",
       " 'igual': 247,\n",
       " 'he': 248,\n",
       " 'd': 249,\n",
       " 'camote': 250,\n",
       " 'Los': 251,\n",
       " 'veo': 252,\n",
       " 'personas': 253,\n",
       " 'pasa': 254,\n",
       " 'hacen': 255,\n",
       " 'ha': 256,\n",
       " 'donde': 257,\n",
       " 'digo': 258,\n",
       " 'Hoy': 259,\n",
       " '/': 260,\n",
       " 'v': 261,\n",
       " 'unas': 262,\n",
       " 'bueno': 263,\n",
       " ':(': 264,\n",
       " 'fotos': 265,\n",
       " 'cabrón': 266,\n",
       " 'Ahora': 267,\n",
       " 'otro': 268,\n",
       " 'mismo': 269,\n",
       " 'cabron': 270,\n",
       " 'buena': 271,\n",
       " 'ahí': 272,\n",
       " 'trabajo': 273,\n",
       " 'sabe': 274,\n",
       " 'nadie': 275,\n",
       " 'estas': 276,\n",
       " 'desde': 277,\n",
       " 'amigos': 278,\n",
       " 'alv': 279,\n",
       " 'Pinche': 280,\n",
       " 'mí': 281,\n",
       " 'hombres': 282,\n",
       " 'foto': 283,\n",
       " 'culo': 284,\n",
       " 'casa': 285,\n",
       " 'ardida': 286,\n",
       " 'Jajaja': 287,\n",
       " '*': 288,\n",
       " '😈': 289,\n",
       " 've': 290,\n",
       " 'valer': 291,\n",
       " 'han': 292,\n",
       " 'fuera': 293,\n",
       " 'e': 294,\n",
       " 'chingar': 295,\n",
       " 'Pues': 296,\n",
       " 'Esta': 297,\n",
       " 'pendejos': 298,\n",
       " 'mames': 299,\n",
       " 'ella': 300,\n",
       " 'cara': 301,\n",
       " '🤣': 302,\n",
       " 'sólo': 303,\n",
       " 'mil': 304,\n",
       " 'súper': 305,\n",
       " 'rico': 306,\n",
       " 'noche': 307,\n",
       " 'mundial': 308,\n",
       " 'luego': 309,\n",
       " 'jajajaja': 310,\n",
       " 'fin': 311,\n",
       " 'estos': 312,\n",
       " 'encanta': 313,\n",
       " 'amigo': 314,\n",
       " 'Tu': 315,\n",
       " 'EL': 316,\n",
       " '😩': 317,\n",
       " '🎶': 318,\n",
       " 'ustedes': 319,\n",
       " 'semana': 320,\n",
       " 'quieren': 321,\n",
       " 'pueden': 322,\n",
       " 'mientras': 323,\n",
       " 'aquí': 324,\n",
       " 'antes': 325,\n",
       " 'dan': 326,\n",
       " 'Para': 327,\n",
       " 'Porque': 328,\n",
       " 'Gracias': 329,\n",
       " 'persona': 330,\n",
       " 'jaja': 331,\n",
       " 'gay': 332,\n",
       " 'dinero': 333,\n",
       " 'dijo': 334,\n",
       " 'creo': 335,\n",
       " 'buen': 336,\n",
       " 'amo': 337,\n",
       " 'YA': 338,\n",
       " 'PUTA': 339,\n",
       " 'ven': 340,\n",
       " 'sabes': 341,\n",
       " 'novio': 342,\n",
       " 'dar': 343,\n",
       " 'creen': 344,\n",
       " 'chingo': 345,\n",
       " 'caga': 346,\n",
       " 'Un': 347,\n",
       " 'Está': 348,\n",
       " 'Con': 349,\n",
       " 'Así': 350,\n",
       " 'unos': 351,\n",
       " 'putita': 352,\n",
       " 'perra': 353,\n",
       " 'peor': 354,\n",
       " 'gata': 355,\n",
       " 'falta': 356,\n",
       " 'digan': 357,\n",
       " 'deja': 358,\n",
       " 'aún': 359,\n",
       " 'amiga': 360,\n",
       " 'Soy': 361,\n",
       " 'Putas': 362,\n",
       " 'EN': 363,\n",
       " '4': 364,\n",
       " '1': 365,\n",
       " '😠': 366,\n",
       " 'triste': 367,\n",
       " 'puedes': 368,\n",
       " 'mamen': 369,\n",
       " 'horas': 370,\n",
       " 'hablar': 371,\n",
       " 'entiendo': 372,\n",
       " 'dejar': 373,\n",
       " 'sean': 374,\n",
       " 'saben': 375,\n",
       " 'quién': 376,\n",
       " 'pelan': 377,\n",
       " 'país': 378,\n",
       " 'novia': 379,\n",
       " 'hora': 380,\n",
       " 'haciendo': 381,\n",
       " 'dormir': 382,\n",
       " 'después': 383,\n",
       " 'andar': 384,\n",
       " 'Ni': 385,\n",
       " '5': 386,\n",
       " '🇲🇽': 387,\n",
       " 'viendo': 388,\n",
       " 'vamos': 389,\n",
       " 'tarea': 390,\n",
       " 'tal': 391,\n",
       " 'prieta': 392,\n",
       " 'mamadas': 393,\n",
       " 'gusto': 394,\n",
       " 'cosa': 395,\n",
       " 'asi': 396,\n",
       " 'asco': 397,\n",
       " 'Ojalá': 398,\n",
       " 'Hay': 399,\n",
       " '😤': 400,\n",
       " '😘': 401,\n",
       " 'valió': 402,\n",
       " 'señora': 403,\n",
       " 'saber': 404,\n",
       " 'rica': 405,\n",
       " 'palabra': 406,\n",
       " 'nalgas': 407,\n",
       " 'maricón': 408,\n",
       " 'hago': 409,\n",
       " 'había': 410,\n",
       " 'ellos': 411,\n",
       " 'cómo': 412,\n",
       " 'boca': 413,\n",
       " 'SU': 414,\n",
       " 'LOS': 415,\n",
       " '#MasterChefMx': 416,\n",
       " '😏': 417,\n",
       " 'poca': 418,\n",
       " 'perro': 419,\n",
       " 'mandar': 420,\n",
       " 'llorar': 421,\n",
       " 'hombre': 422,\n",
       " 'chingas': 423,\n",
       " 'año': 424,\n",
       " 'Todos': 425,\n",
       " 'Tengo': 426,\n",
       " 'Pinches': 427,\n",
       " '😌': 428,\n",
       " '💔': 429,\n",
       " '🍆': 430,\n",
       " 'él': 431,\n",
       " 'vergas': 432,\n",
       " 'sigue': 433,\n",
       " 'risa': 434,\n",
       " 're': 435,\n",
       " 'quieres': 436,\n",
       " 'queda': 437,\n",
       " 'puro': 438,\n",
       " 'ponen': 439,\n",
       " 'pone': 440,\n",
       " 'otras': 441,\n",
       " 'odio': 442,\n",
       " 'misma': 443,\n",
       " 'miedo': 444,\n",
       " 'iba': 445,\n",
       " 'hubiera': 446,\n",
       " 'golfa': 447,\n",
       " 'ex': 448,\n",
       " 'dejen': 449,\n",
       " 'debe': 450,\n",
       " 'bonito': 451,\n",
       " 'PARA': 452,\n",
       " 'siguen': 453,\n",
       " 'pobre': 454,\n",
       " 'parte': 455,\n",
       " 'importa': 456,\n",
       " 'hizo': 457,\n",
       " 'hija': 458,\n",
       " 'feo': 459,\n",
       " 'feliz': 460,\n",
       " 'fea': 461,\n",
       " 'favor': 462,\n",
       " 'culpa': 463,\n",
       " 'Quiero': 464,\n",
       " 'Este': 465,\n",
       " 'Alguien': 466,\n",
       " '10': 467,\n",
       " '🔥': 468,\n",
       " 'vieja': 469,\n",
       " 'valiendo': 470,\n",
       " 'tarde': 471,\n",
       " 'seguro': 472,\n",
       " 'salir': 473,\n",
       " 'puñal': 474,\n",
       " 'poner': 475,\n",
       " 'pensar': 476,\n",
       " 'partido': 477,\n",
       " 'minutos': 478,\n",
       " 'lugar': 479,\n",
       " 'llega': 480,\n",
       " 'diga': 481,\n",
       " 'chinga': 482,\n",
       " 'canción': 483,\n",
       " 'ando': 484,\n",
       " 'anda': 485,\n",
       " 'RT': 486,\n",
       " 'PUTO': 487,\n",
       " 'Eso': 488,\n",
       " '$': 489,\n",
       " '🙃': 490,\n",
       " '😞': 491,\n",
       " '😔': 492,\n",
       " 'somos': 493,\n",
       " 'sido': 494,\n",
       " 'pena': 495,\n",
       " 'parece': 496,\n",
       " 'momento': 497,\n",
       " 'mando': 498,\n",
       " 'lameculos': 499,\n",
       " 'huevos': 500,\n",
       " 'hermano': 501,\n",
       " 'familia': 502,\n",
       " 'entre': 503,\n",
       " 'contigo': 504,\n",
       " 'bonita': 505,\n",
       " 'agua': 506,\n",
       " 'acabo': 507,\n",
       " 'Siempre': 508,\n",
       " 'Neta': 509,\n",
       " 'Les': 510,\n",
       " 'Le': 511,\n",
       " 'Hasta': 512,\n",
       " 'ES': 513,\n",
       " '🤦🏻\\u200d♀': 514,\n",
       " '😎': 515,\n",
       " '💦': 516,\n",
       " '|': 517,\n",
       " 'volver': 518,\n",
       " 'visto': 519,\n",
       " 'viejas': 520,\n",
       " 'ves': 521,\n",
       " 'valen': 522,\n",
       " 'sobre': 523,\n",
       " 'servicio': 524,\n",
       " 'seas': 525,\n",
       " 'sale': 526,\n",
       " 'primera': 527,\n",
       " 'pongo': 528,\n",
       " 'poder': 529,\n",
       " 'perros': 530,\n",
       " 'pasan': 531,\n",
       " 'pasado': 532,\n",
       " 'nuevo': 533,\n",
       " 'mama': 534,\n",
       " 'lado': 535,\n",
       " 'fui': 536,\n",
       " 'forma': 537,\n",
       " 'escuela': 538,\n",
       " 'escuchar': 539,\n",
       " 'dije': 540,\n",
       " 'dicho': 541,\n",
       " 'dices': 542,\n",
       " 'conmigo': 543,\n",
       " 'Twitter': 544,\n",
       " 'TU': 545,\n",
       " 'Solo': 546,\n",
       " 'SE': 547,\n",
       " 'Jajajajaja': 548,\n",
       " 'Gorda': 549,\n",
       " 'Dios': 550,\n",
       " 'Cómo': 551,\n",
       " 'Creo': 552,\n",
       " 'Ay': 553,\n",
       " 'Aquí': 554,\n",
       " 'Ah': 555,\n",
       " '7': 556,\n",
       " '20': 557,\n",
       " '😱': 558,\n",
       " 'vista': 559,\n",
       " 'video': 560,\n",
       " 'valgo': 561,\n",
       " 'tanta': 562,\n",
       " 'sigo': 563,\n",
       " 'será': 564,\n",
       " 'rato': 565,\n",
       " 'problema': 566,\n",
       " 'pa': 567,\n",
       " 'otros': 568,\n",
       " 'música': 569,\n",
       " 'llevo': 570,\n",
       " 'lleva': 571,\n",
       " 'jajajajaja': 572,\n",
       " 'hecho': 573,\n",
       " 'haga': 574,\n",
       " 'haber': 575,\n",
       " 'grande': 576,\n",
       " 'gracias': 577,\n",
       " 'entonces': 578,\n",
       " 'doy': 579,\n",
       " 'diciendo': 580,\n",
       " 'chiflar': 581,\n",
       " 'cagan': 582,\n",
       " 'buenas': 583,\n",
       " 'andan': 584,\n",
       " 'amigas': 585,\n",
       " 'V': 586,\n",
       " 'Su': 587,\n",
       " 'POR': 588,\n",
       " 'PINCHE': 589,\n",
       " 'LOCA': 590,\n",
       " 'JAJAJA': 591,\n",
       " '🙊': 592,\n",
       " '😣': 593,\n",
       " '☹': 594,\n",
       " 'único': 595,\n",
       " 'xD': 596,\n",
       " 'vi': 597,\n",
       " 'tres': 598,\n",
       " 'trabajar': 599,\n",
       " 'siendo': 600,\n",
       " 'seguir': 601,\n",
       " 'quiera': 602,\n",
       " 'quería': 603,\n",
       " 'primero': 604,\n",
       " 'papá': 605,\n",
       " 'padre': 606,\n",
       " 'ojalá': 607,\n",
       " 'niño': 608,\n",
       " 'niñas': 609,\n",
       " 'niña': 610,\n",
       " 'meter': 611,\n",
       " 'hablando': 612,\n",
       " 'final': 613,\n",
       " 'estamos': 614,\n",
       " 'demás': 615,\n",
       " 'das': 616,\n",
       " 'comer': 617,\n",
       " 'clase': 618,\n",
       " 'caso': 619,\n",
       " 'casi': 620,\n",
       " 'UN': 621,\n",
       " 'TE': 622,\n",
       " 'Mis': 623,\n",
       " 'Marica': 624,\n",
       " 'LO': 625,\n",
       " 'LAS': 626,\n",
       " 'Eres': 627,\n",
       " 'COMO': 628,\n",
       " '😬': 629,\n",
       " '😢': 630,\n",
       " '😊': 631,\n",
       " '😁': 632,\n",
       " 'viejo': 633,\n",
       " 'tipo': 634,\n",
       " 'sola': 635,\n",
       " 'respeto': 636,\n",
       " 'razón': 637,\n",
       " 'pasar': 638,\n",
       " 'palabras': 639,\n",
       " 'pagar': 640,\n",
       " 'nombre': 641,\n",
       " 'noches': 642,\n",
       " 'medio': 643,\n",
       " 'mano': 644,\n",
       " 'llama': 645,\n",
       " 'huevo': 646,\n",
       " 'hambre': 647,\n",
       " 'haces': 648,\n",
       " 'esperando': 649,\n",
       " 'equipo': 650,\n",
       " 'cualquier': 651,\n",
       " 'creer': 652,\n",
       " 'chinguen': 653,\n",
       " 'chica': 654,\n",
       " 'celular': 655,\n",
       " 'calle': 656,\n",
       " 'aunque': 657,\n",
       " 'ardidas': 658,\n",
       " 'Sí': 659,\n",
       " 'Quien': 660,\n",
       " 'Puto': 661,\n",
       " 'Mira': 662,\n",
       " 'Mañana': 663,\n",
       " 'Esa': 664,\n",
       " 'Al': 665,\n",
       " '6': 666,\n",
       " '&': 667,\n",
       " '🤤': 668,\n",
       " '😜': 669,\n",
       " 'vos': 670,\n",
       " 'videos': 671,\n",
       " 'vaya': 672,\n",
       " 'tenía': 673,\n",
       " 'siente': 674,\n",
       " 'punto': 675,\n",
       " 'porqué': 676,\n",
       " 'poco': 677,\n",
       " 'paso': 678,\n",
       " 'partir': 679,\n",
       " 'parecen': 680,\n",
       " 'ojos': 681,\n",
       " 'nosotros': 682,\n",
       " 'maldito': 683,\n",
       " 'lluvia': 684,\n",
       " 'hice': 685,\n",
       " 'gordas': 686,\n",
       " 'estan': 687,\n",
       " 'estado': 688,\n",
       " 'eran': 689,\n",
       " 'ellas': 690,\n",
       " 'dónde': 691,\n",
       " 'den': 692,\n",
       " 'deberían': 693,\n",
       " 'culero': 694,\n",
       " 'corazón': 695,\n",
       " 'clases': 696,\n",
       " 'cargo': 697,\n",
       " 'cae': 698,\n",
       " 'ayer': 699,\n",
       " 'además': 700,\n",
       " 'Todo': 701,\n",
       " 'Teresa': 702,\n",
       " 'TODOS': 703,\n",
       " 'SI': 704,\n",
       " 'Puta': 705,\n",
       " 'Jajajajajaja': 706,\n",
       " 'HIJO': 707,\n",
       " 'CON': 708,\n",
       " '@': 709,\n",
       " '😪': 710,\n",
       " '😕': 711,\n",
       " '😋': 712,\n",
       " 'x': 713,\n",
       " 'vuelve': 714,\n",
       " 'viene': 715,\n",
       " 'usar': 716,\n",
       " 'tengan': 717,\n",
       " 'tenemos': 718,\n",
       " 'tambien': 719,\n",
       " 'tacos': 720,\n",
       " 'sueño': 721,\n",
       " 'serio': 722,\n",
       " 'salen': 723,\n",
       " 'sabemos': 724,\n",
       " 'pura': 725,\n",
       " 'pueblo': 726,\n",
       " 'poniendo': 727,\n",
       " 'políticos': 728,\n",
       " 'pienso': 729,\n",
       " 'periodistas': 730,\n",
       " 'pendejas': 731,\n",
       " 'nivel': 732,\n",
       " 'meses': 733,\n",
       " 'mes': 734,\n",
       " 'mariquita': 735,\n",
       " 'lleno': 736,\n",
       " 'llegar': 737,\n",
       " 'juego': 738,\n",
       " 'historia': 739,\n",
       " 'hermoso': 740,\n",
       " 'hagan': 741,\n",
       " 'grupo': 742,\n",
       " 'fan': 743,\n",
       " 'espero': 744,\n",
       " 'escribir': 745,\n",
       " 'dio': 746,\n",
       " 'demasiado': 747,\n",
       " 'deje': 748,\n",
       " 'dado': 749,\n",
       " 'contra': 750,\n",
       " 'arruga': 751,\n",
       " 'Wey': 752,\n",
       " 'Son': 753,\n",
       " 'Quién': 754,\n",
       " 'HIJOS': 755,\n",
       " 'Chinga': 756,\n",
       " 'ALV': 757,\n",
       " '🙈': 758,\n",
       " '😻': 759,\n",
       " '😅': 760,\n",
       " '💕': 761,\n",
       " 'volviendo': 762,\n",
       " 'vato': 763,\n",
       " 'tuits': 764,\n",
       " 'tenga': 765,\n",
       " 'salió': 766,\n",
       " 'putito': 767,\n",
       " 'primer': 768,\n",
       " 'pones': 769,\n",
       " 'pesos': 770,\n",
       " 'pela': 771,\n",
       " 'partidos': 772,\n",
       " 'nuestros': 773,\n",
       " 'nuestro': 774,\n",
       " 'necesito': 775,\n",
       " 'muchas': 776,\n",
       " 'morra': 777,\n",
       " 'moral': 778,\n",
       " 'mayor': 779,\n",
       " 'matar': 780,\n",
       " 'manos': 781,\n",
       " 'mamo': 782,\n",
       " 'mamaste': 783,\n",
       " 'maldita': 784,\n",
       " 'mala': 785,\n",
       " 'leche': 786,\n",
       " 'lados': 787,\n",
       " 'hermosa': 788,\n",
       " 'has': 789,\n",
       " 'gran': 790,\n",
       " 'golfas': 791,\n",
       " 'fútbol': 792,\n",
       " 'fueron': 793,\n",
       " 'frío': 794,\n",
       " 'diario': 795,\n",
       " 'dejan': 796,\n",
       " 'darle': 797,\n",
       " 'dando': 798,\n",
       " 'costumbre': 799,\n",
       " 'cierto': 800,\n",
       " 'chingue': 801,\n",
       " 'cabeza': 802,\n",
       " 'buenos': 803,\n",
       " 'bola': 804,\n",
       " 'baño': 805,\n",
       " 'acabar': 806,\n",
       " 'Vale': 807,\n",
       " 'Tú': 808,\n",
       " 'SUS': 809,\n",
       " 'Mamá': 810,\n",
       " 'MI': 811,\n",
       " 'Jaja': 812,\n",
       " 'Esos': 813,\n",
       " 'Esas': 814,\n",
       " 'Desde': 815,\n",
       " 'Bueno': 816,\n",
       " '>': 817,\n",
       " '🤷🏻\\u200d♀': 818,\n",
       " '🤗': 819,\n",
       " '😑': 820,\n",
       " '😉': 821,\n",
       " '👏': 822,\n",
       " 'xq': 823,\n",
       " 'we': 824,\n",
       " 'vivo': 825,\n",
       " 'vayan': 826,\n",
       " 'tuve': 827,\n",
       " 'tristes': 828,\n",
       " 'tantos': 829,\n",
       " 'tantas': 830,\n",
       " 'suerte': 831,\n",
       " 'siquiera': 832,\n",
       " 'sienten': 833,\n",
       " 'saca': 834,\n",
       " 'ropa': 835,\n",
       " 'puras': 836,\n",
       " 'perder': 837,\n",
       " 'pensé': 838,\n",
       " 'paz': 839,\n",
       " 'pase': 840,\n",
       " 'nueva': 841,\n",
       " 'niños': 842,\n",
       " 'ningún': 843,\n",
       " 'mandan': 844,\n",
       " 'mamó': 845,\n",
       " 'mamada': 846,\n",
       " 'llorando': 847,\n",
       " 'jugar': 848,\n",
       " 'jamás': 849,\n",
       " 'hondureños': 850,\n",
       " 'hermana': 851,\n",
       " 'habla': 852,\n",
       " 'gustan': 853,\n",
       " 'gobierno': 854,\n",
       " 'frase': 855,\n",
       " 'examen': 856,\n",
       " 'empieza': 857,\n",
       " 'dijeron': 858,\n",
       " 'darme': 859,\n",
       " 'cual': 860,\n",
       " 'comiendo': 861,\n",
       " 'chile': 862,\n",
       " 'caracteres': 863,\n",
       " 'cagada': 864,\n",
       " 'bonitas': 865,\n",
       " 'Sabes': 866,\n",
       " 'Q': 867,\n",
       " 'Nunca': 868,\n",
       " 'Nada': 869,\n",
       " 'Más': 870,\n",
       " 'Messi': 871,\n",
       " 'Esto': 872,\n",
       " 'Ese': 873,\n",
       " 'DEL': 874,\n",
       " 'Chingas': 875,\n",
       " 'Chile': 876,\n",
       " 'Cada': 877,\n",
       " 'Amo': 878,\n",
       " '8': 879,\n",
       " '😖': 880,\n",
       " '😐': 881,\n",
       " '💖': 882,\n",
       " '👌': 883,\n",
       " '☺': 884,\n",
       " 'váyanse': 885,\n",
       " 'vuelven': 886,\n",
       " 'vivir': 887,\n",
       " 'venir': 888,\n",
       " 'vemos': 889,\n",
       " 'valga': 890,\n",
       " 'usan': 891,\n",
       " 'tweets': 892,\n",
       " 'trae': 893,\n",
       " 'todavía': 894,\n",
       " 'temprano': 895,\n",
       " 'sigues': 896,\n",
       " 'sería': 897,\n",
       " 'seria': 898,\n",
       " 'salgo': 899,\n",
       " 'querer': 900,\n",
       " 'prietas': 901,\n",
       " 'peda': 902,\n",
       " 'pasó': 903,\n",
       " 'normal': 904,\n",
       " 'naturaleza': 905,\n",
       " 'mía': 906,\n",
       " 'mucha': 907,\n",
       " 'mira': 908,\n",
       " 'mente': 909,\n",
       " 'mentada': 910,\n",
       " 'juntos': 911,\n",
       " 'ja': 912,\n",
       " 'imagen': 913,\n",
       " 'horrible': 914,\n",
       " 'haya': 915,\n",
       " 'hacerlo': 916,\n",
       " 'hablas': 917,\n",
       " 'hablan': 918,\n",
       " 'gringos': 919,\n",
       " 'gatos': 920,\n",
       " 'fuerte': 921,\n",
       " 'extraño': 922,\n",
       " 'etc': 923,\n",
       " 'esté': 924,\n",
       " 'estaría': 925,\n",
       " 'esperar': 926,\n",
       " 'empiezan': 927,\n",
       " 'edad': 928,\n",
       " 'duele': 929,\n",
       " 'diferente': 930,\n",
       " 'dieron': 931,\n",
       " 'derechos': 932,\n",
       " 'dentro': 933,\n",
       " 'cuerpo': 934,\n",
       " 'critican': 935,\n",
       " 'cree': 936,\n",
       " 'clima': 937,\n",
       " 'claro': 938,\n",
       " 'carro': 939,\n",
       " 'cagas': 940,\n",
       " 'ayuda': 941,\n",
       " 'am': 942,\n",
       " 'algún': 943,\n",
       " 'alguna': 944,\n",
       " 'alcohol': 945,\n",
       " 'acaba': 946,\n",
       " 'UNA': 947,\n",
       " 'Todas': 948,\n",
       " 'También': 949,\n",
       " 'Sólo': 950,\n",
       " 'Nos': 951,\n",
       " 'Mejor': 952,\n",
       " 'Loca': 953,\n",
       " 'Gente': 954,\n",
       " 'Facebook': 955,\n",
       " 'Están': 956,\n",
       " 'Cosas': 957,\n",
       " 'Calcuta': 958,\n",
       " 'Buenos': 959,\n",
       " 'Ando': 960,\n",
       " '280': 961,\n",
       " '🤦🏻\\u200d♂': 962,\n",
       " '🙂': 963,\n",
       " '😓': 964,\n",
       " '🐷': 965,\n",
       " '🎵': 966,\n",
       " '✊🏼': 967,\n",
       " '—': 968,\n",
       " 'única': 969,\n",
       " 'vergüenza': 970,\n",
       " 'vergazos': 971,\n",
       " 'tráfico': 972,\n",
       " 'tobogán': 973,\n",
       " 'teléfono': 974,\n",
       " 't': 975,\n",
       " 'super': 976,\n",
       " 'subir': 977,\n",
       " 'sigan': 978,\n",
       " 'señor': 979,\n",
       " 'sexo': 980,\n",
       " 'sentir': 981,\n",
       " 'sentido': 982,\n",
       " 'selección': 983,\n",
       " 'sabía': 984,\n",
       " 'regreso': 985,\n",
       " 'realidad': 986,\n",
       " 'rateros': 987,\n",
       " 'queriendo': 988,\n",
       " 'puso': 989,\n",
       " 'puse': 990,\n",
       " 'puesto': 991,\n",
       " 'presidente': 992,\n",
       " 'porno': 993,\n",
       " 'ponerme': 994,\n",
       " 'placer': 995,\n",
       " 'piensan': 996,\n",
       " 'piel': 997,\n",
       " 'pesar': 998,\n",
       " 'pensando': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_indices = dict()\n",
    "count = 0\n",
    "\n",
    "for weight, word in voc:\n",
    "    dict_indices[word] = count\n",
    "    count += 1\n",
    "\n",
    "dict_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bow con scikit\n",
    "\n",
    "La bolsa de palabras es un modelo que simplifica el contenido textual al considerar solo la ocurrencia de palabras, ignorando su orden y contexto. En este modelo, un texto se representa como un vector, donde cada dimensión corresponde a una palabra del vocabulario de todos los textos considerados, y el valor en cada dimensión cuenta la frecuencia de esa palabra en el texto.\n",
    "\n",
    "Para construir una bolsa de palabras en `scikit-learn`, se puede usar la clase `CountVectorizer`:\n",
    "\n",
    "1. **Importar `CountVectorizer`**: Primero, es necesario importar la clase `CountVectorizer` de `sklearn.feature_extraction.text`.\n",
    "\n",
    "2. **Instanciar `CountVectorizer`**: Luego, se crea una instancia de `CountVectorizer`. Se puede personalizar varios parámetros, como `max_features` para limitar el número de palabras en el vocabulario, `stop_words` para excluir palabras comunes que no aportan mucho significado (como \"y\", \"o\", \"el\", etc.), y `ngram_range` para considerar combinaciones de palabras además de palabras individuales.\n",
    "\n",
    "3. **Ajustar el modelo**: Se ajusta el vectorizador a los documentos de texto con el método `.fit()`, lo que hace que el modelo aprenda el vocabulario.\n",
    "\n",
    "4. **Transformar textos**: Finalmente, se transforman los documentos de texto en vectores BoW utilizando el método `.transform()`. Esto convierte cada texto en un vector numérico donde cada elemento representa la frecuencia de una palabra del vocabulario en el texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario: ['aprendizaje' 'automático' 'del' 'el' 'es' 'facilita' 'fascinante'\n",
      " 'learn' 'learning' 'lenguaje' 'machine' 'natural' 'parte' 'procesamiento'\n",
      " 'scikit' 'una']\n",
      "Bolsa de palabras:\n",
      " [[1 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1]\n",
      " [0 0 0 1 0 1 0 1 1 0 1 0 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Ejemplo de documentos\n",
    "documentos = [\n",
    "    \"El aprendizaje automático es fascinante\",\n",
    "    \"El procesamiento de lenguaje natural es una parte del aprendizaje automático\",\n",
    "    \"Scikit-learn facilita el machine learning\"\n",
    "]\n",
    "\n",
    "# Instanciar CountVectorizer\n",
    "vectorizador = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Ajustar el modelo y transformar los documentos en una bolsa de palabras\n",
    "bolsa_de_palabras = vectorizador.fit_transform(documentos)\n",
    "\n",
    "# Convertir la bolsa de palabras a un array para visualizarla\n",
    "array_bolsa_de_palabras = bolsa_de_palabras.toarray()\n",
    "\n",
    "# Obtener el vocabulario\n",
    "vocabulario = vectorizador.get_feature_names_out()\n",
    "\n",
    "print(\"Vocabulario:\", vocabulario)\n",
    "print(\"Bolsa de palabras:\\n\", array_bolsa_de_palabras)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bolsa de términos\n",
    "\n",
    "Con la variable **dict_indices** ya podemos crear la bolsa de palabras. Utilizamos la librería numpy para trabajar con vectores. Construimos la bolsa de palabras en una matriz. La bolsa de palabras que construimos tiene un pesado binario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def build_bow_tr(tr_text, vocabulary, dict_indices):\n",
    "\n",
    "    # Construcción de matriz para la bolsa de palabras\n",
    "    # En cada fila vemos los documentos que estamos procesando\n",
    "    # En las columnas el tamaño del vocabulario que estamos creando\n",
    "    BOW = np.zeros((len(tr_text),len(vocabulary)), dtype = int)\n",
    "\n",
    "    for tr in tr_text:\n",
    "        # Cada documento tr lo tokenizamos\n",
    "        fdist_doc = nltk.FreqDist(tokenizer.tokenize(tr))\n",
    "\n",
    "        # Definimos el contador para cada documento\n",
    "        cont_doc = 0\n",
    "\n",
    "        # Contamos cada palabra\n",
    "        for word in fdist_doc:\n",
    "\n",
    "            # Nos aseguramos que las palabras estan en el diccionario final de 5mil palabras\n",
    "            if word in dict_indices:\n",
    "                BOW[cont_doc, dict_indices[word]] = 1\n",
    "\n",
    "        cont_doc += 1\n",
    "\n",
    "    return BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 1, 1, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BOW_tr = build_bow_tr(tr_text, voc, dict_indices)\n",
    "BOW_tr[:10][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5278, 5000)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BOW_tr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bolsa de palabras de validación\n",
    "\n",
    "Ahora construimos la bolsa de palabras para los términos de validación. Utilizamos el mismo vocabulario y el mismo diccionario que ya construimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 418, 1: 169})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Class')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cargar los archivos de validación\n",
    "\n",
    "path_text = \"/Users/guillermo_sego/Desktop/Segundo Semestre/PLN/MexData/mex20_val.txt\"\n",
    "path_labels = \"/Users/guillermo_sego/Desktop/Segundo Semestre/PLN/MexData/mex20_val_labels.txt\"\n",
    "\n",
    "val_text, val_labels = get_text_from_file(path_text, path_labels)\n",
    "\n",
    "# Hacemos una lista de enteros\n",
    "val_labels = list(map(int, val_labels))\n",
    "\n",
    "print(Counter(val_labels))\n",
    "\n",
    "plt.hist(val_labels, bins=len(set(val_labels)))\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.xlabel(\"Class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOW_val = build_bow_tr(val_text, voc, dict_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación\n",
    "\n",
    "Un clasificador es un algoritmo que se utiliza en machine learning para asignar una categoría o clase a una instancia de datos basándose en sus características. Los clasificadores se entrenan con un conjunto de datos que ya tiene etiquetas de clase conocidas, en un proceso llamado aprendizaje supervisado. Una vez entrenado, el clasificador puede usarse para predecir la clase de nuevas instancias de datos.\n",
    "\n",
    "**Clasificador SVM (Máquinas de Vectores de Soporte)**\n",
    "\n",
    "El clasificador SVM (Support Vector Machine, o Máquinas de Vectores de Soporte en español) es un algoritmo muy popular y potente en el campo del aprendizaje automático. Se utiliza principalmente para problemas de clasificación, pero también puede adaptarse para la regresión.\n",
    "\n",
    "El objetivo principal de un SVM es encontrar el hiperplano óptimo (en 2D sería una línea, en 3D un plano, y así sucesivamente para dimensiones más altas) que separe las clases de datos con el margen más amplio posible. Este hiperplano se define como el que tiene la mayor distancia a los puntos de datos más cercanos de cada clase, conocidos como vectores de soporte.\n",
    "\n",
    "**Funcionamiento Básico del SVM**\n",
    "\n",
    "- **Margen y Vectores de Soporte**: El SVM intenta maximizar el margen entre las clases. Los vectores de soporte son los puntos de datos más cercanos al hiperplano de decisión, y el margen es la distancia entre estos puntos y el hiperplano. Un margen más amplio ofrece mejor generalización, lo que significa que el clasificador tiene mejor capacidad para clasificar correctamente nuevos datos no vistos durante el entrenamiento.\n",
    "\n",
    "- **Kernel Trick**: Una de las características más poderosas del SVM es su capacidad para operar en espacios de características de alta dimensión utilizando funciones kernel. Esto permite al SVM manejar datos que no son linealmente separables en su espacio original, transformándolos a un espacio de mayor dimensión donde sí lo son. Los kernels más comunes incluyen el lineal, polinomial, y el de base radial (RBF).\n",
    "\n",
    "- **Problemas de Clasificación y Regresión**: Aunque SVM se utiliza principalmente para la clasificación, se puede adaptar para la regresión (SVR o Support Vector Regression).\n",
    "\n",
    "**Ejemplo de Uso del SVM en Scikit-learn**\n",
    "\n",
    "Este código carga el conjunto de datos Iris, filtra para quedarse con dos clases para un problema binario, divide los datos en conjuntos de entrenamiento y prueba, los escala (un paso importante para los algoritmos basados en distancia como SVM), y luego entrena y evalúa un clasificador SVM con un kernel lineal.\n",
    "\n",
    "Los clasificadores, incluido el SVM, son herramientas esenciales en machine learning y tienen una amplia gama de aplicaciones, desde reconocimiento de imágenes y voz hasta clasificación de textos y más allá."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del clasificador SVM: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Cargar un conjunto de datos de ejemplo\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Para simplificar, nos quedamos solo con dos clases\n",
    "X = X[y != 2]\n",
    "y = y[y != 2]\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Escalar los datos para mejorar el rendimiento del SVM\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Entrenar un clasificador SVM\n",
    "svm_clf = SVC(kernel='linear')  # Usar el kernel lineal\n",
    "svm_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluar el clasificador\n",
    "accuracy = svm_clf.score(X_test_scaled, y_test)\n",
    "print(f\"Precisión del clasificador SVM: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder ejecutar correctamente la clasificación necesitamos que la lista **tr_labels** sea una lista de enteros y asi tener solo las clases 0 y 1. La lista de validación **tr_val** ya se formateo correctamente a enteros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_labels = list(map(int, tr_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos la libería **sklearn** para construir la máquina de soporte vectorial. \n",
    "\n",
    "`Scikit-learn` (importado generalmente como `sklearn`) es una biblioteca de Python muy popular para machine learning. Ofrece una amplia gama de algoritmos tanto para aprendizaje supervisado (como clasificación y regresión) como no supervisado (como agrupamiento y reducción de dimensionalidad), junto con herramientas para la selección de modelos, preprocesamiento de datos, evaluación de modelos y muchas otras utilidades.\n",
    "\n",
    "A continuación, te explico brevemente cada uno de los componentes de `scikit-learn` que mencionaste, enfocándome en cómo se utilizan en el contexto de clasificar una bolsa de palabras:\n",
    "\n",
    "### 1. `svm`\n",
    "\n",
    "El módulo `svm` de `scikit-learn` proporciona clases para diferentes tipos de Máquinas de Vectores de Soporte (SVM), que es un conjunto poderoso de algoritmos utilizados para clasificación, regresión y detección de outliers. En el contexto de clasificación de una bolsa de palabras, podrías usar `SVC` (Support Vector Classification) para clasificar textos en diferentes categorías."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0 0 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0 1 1 0 0 1 0 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# Crear una instancia del clasificador SVM\n",
    "clf = svm.SVC(kernel='linear')  # El kernel puede ser 'linear', 'poly', 'rbf', 'sigmoid', etc.\n",
    "\n",
    "# Entrenar el clasificador con los datos de entrenamiento\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predecir las etiquetas para los datos de prueba\n",
    "y_pred = clf.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. `model_selection.GridSearchCV`\n",
    "\n",
    "`GridSearchCV` es una herramienta que te permite encontrar los mejores parámetros para tu modelo de forma automatizada. Realiza una búsqueda exhaustiva sobre los parámetros especificados de un modelo para encontrar la combinación que da los mejores resultados de acuerdo con una métrica de evaluación determinada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.001, kernel=linear; total time=   0.0s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definir el espacio de parámetros para la búsqueda\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],  # Regularización\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],  # Parámetro para el kernel 'rbf'\n",
    "    'kernel': ['rbf', 'linear']  # Tipo de kernel\n",
    "}\n",
    "\n",
    "# Crear una instancia de GridSearchCV\n",
    "grid_search = GridSearchCV(svm.SVC(), param_grid, refit=True, verbose=2)\n",
    "\n",
    "# Ejecutar la búsqueda en los datos de entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtener el mejor clasificador\n",
    "best_clf = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. `metrics`\n",
    "\n",
    "El módulo `metrics` incluye una variedad de funciones de puntuación, métricas de pérdida y utilidades para medir el rendimiento de tu modelo. Estas métricas son cruciales para evaluar qué tan bien tu modelo está clasificando los datos.\n",
    "\n",
    "- **`accuracy_score`**: Mide la precisión general del modelo, es decir, la proporción de predicciones correctas.\n",
    "- **`confusion_matrix`**: Proporciona una matriz que muestra las clasificaciones correctas e incorrectas entre las clases reales y las predichas.\n",
    "- **`f1_score`**: Es una medida que combina la precisión y la exhaustividad (recall) para dar una sola puntuación que balancea ambas.\n",
    "- **`precision_recall_fscore_support`**: Calcula la precisión, la exhaustividad, el puntaje F1 y el soporte para cada clase.\n",
    "- **`roc_auc_score`**: Mide el área bajo la curva ROC (Receiver Operating Characteristic), que es útil para evaluar la calidad de las predicciones de un clasificador en términos de su capacidad para distinguir entre clases.\n",
    "\n",
    "Ejemplo de uso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 1.0\n",
      "Matriz de Confusión:\n",
      "[[17  0]\n",
      " [ 0 13]]\n",
      "F1 Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "\n",
    "# Precisión\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_test, y_pred, average='binary')  # 'average' puede ser 'micro', 'macro', 'weighted', dependiendo del problema\n",
    "\n",
    "print(f\"Precisión: {accuracy}\")\n",
    "print(f\"Matriz de Confusión:\\n{conf_matrix}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada una de estas funciones y clases de `scikit-learn` es muy poderosa y puede ser personalizada de muchas maneras para adaptarse a las necesidades específicas de tu problema de clasificación. Es importante experimentar con diferentes configuraciones y evaluar tu modelo con varias métricas para obtener una comprensión completa de su rendimiento.\n",
    "\n",
    "Si ahora aplicamos esto a nuestro modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_recall_fscore_support, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queremos ajustar el parámetro $c$ de complejidad. Utilizamos GridSearchCV para esto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83       418\n",
      "           1       1.00      0.01      0.01       169\n",
      "\n",
      "    accuracy                           0.71       587\n",
      "   macro avg       0.86      0.50      0.42       587\n",
      "weighted avg       0.80      0.71      0.60       587\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "parameters = {'C': [0.05, .12, .25, .5, 1, 2, 4]}\n",
    "\n",
    "# Máquina de soporte vectorial\n",
    "srv = svm.LinearSVC(class_weight='balanced')\n",
    "grid = GridSearchCV(estimator=srv, param_grid=parameters, n_jobs = 8, scoring = \"f1_macro\",cv = 5)\n",
    "\n",
    "# Hacer la búsqueda sobre la bolsa de palabras\n",
    "grid.fit(BOW_tr, tr_labels)\n",
    "\n",
    "y_pred = grid.predict(BOW_val)\n",
    "\n",
    "p, r, f, _ = precision_recall_fscore_support(val_labels, y_pred, average=\"macro\", pos_label = 1)\n",
    "print(metrics.classification_report(val_labels, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este informe de clasificación muestra las métricas de rendimiento de un clasificador SVM que se ha entrenado y probado en un conjunto de datos de tweets, donde se intenta predecir si un tweet es agresivo (clase 1) o no agresivo (clase 0). A continuación, interpretación:\n",
    "\n",
    "### Por Clase:\n",
    "\n",
    "- **Clase 0 (No agresivo)**:\n",
    "  - **Precision**: La precisión es del 71%, lo que significa que, de todas las instancias clasificadas como no agresivas por el modelo, el 71% realmente eran no agresivas.\n",
    "  - **Recall**: El recall es del 100%, indicando que el modelo identificó correctamente el 100% de todos los tweets no agresivos en el conjunto de datos.\n",
    "  - **F1-Score**: El F1-score, que combina precisión y recall en una sola métrica, es del 83%. Un valor alto sugiere un buen equilibrio entre precisión y recall.\n",
    "\n",
    "- **Clase 1 (Agresivo)**:\n",
    "  - **Precision**: La precisión es del 100%, lo que significa que todos los tweets que el modelo identificó como agresivos eran realmente agresivos. Sin embargo, esta alta precisión puede ser engañosa debido al muy bajo recall.\n",
    "  - **Recall**: El recall es extremadamente bajo, solo del 1%, lo que indica que el modelo apenas identificó correctamente los tweets agresivos presentes en el conjunto de datos.\n",
    "  - **F1-Score**: El F1-score es del 1%, lo cual es muy bajo y refleja el pobre rendimiento del modelo en la detección de tweets agresivos debido al bajo recall.\n",
    "\n",
    "### Promedios:\n",
    "\n",
    "- **Accuracy**: La precisión general del modelo es del 71%, lo que significa que el 71% de todas las predicciones realizadas por el modelo fueron correctas. Sin embargo, esta métrica puede ser engañosa en conjuntos de datos desequilibrados donde una clase es mucho más prevalente.\n",
    "\n",
    "- **Macro Avg**:\n",
    "  - La precisión macro promedio es del 86%, y el recall macro promedio es del 50%, lo que resulta en un F1-score macro promedio del 42%. El promedio macro trata a todas las clases por igual, sin tener en cuenta el desbalance entre clases. Aunque la precisión macro parece alta, el recall bajo para la clase agresiva reduce significativamente el F1-score macro.\n",
    "\n",
    "- **Weighted Avg**:\n",
    "  - La precisión ponderada promedio es del 80%, y el recall ponderada promedio (igual a la precisión general) es del 71%, con un F1-score ponderado promedio del 60%. Estos promedios ponderados tienen en cuenta el soporte (número de instancias) de cada clase, por lo que dan más peso a la clase más prevalente (no agresiva en este caso).\n",
    "\n",
    "### Interpretación y Consideraciones:\n",
    "\n",
    "El modelo tiene un excelente rendimiento para identificar tweets no agresivos, pero lucha significativamente para identificar tweets agresivos, como lo demuestra el recall extremadamente bajo para la clase 1. Esto podría deberse a varias razones, como un desequilibrio en el conjunto de datos (mucho más tweets no agresivos que agresivos), características no informativas para la clase agresiva, o la necesidad de ajustar mejor los parámetros del modelo.\n",
    "\n",
    "Dado el contexto de la clasificación de agresividad en tweets, es crucial mejorar el recall para la clase agresiva sin sacrificar demasiado la precisión, ya que identificar correctamente los tweets agresivos es vital para la aplicación práctica de este modelo.\n",
    "\n",
    "Para mejorar el rendimiento en la clase agresiva, podrías considerar las siguientes estrategias:\n",
    "- **Rebalanceo de clases**: Utilizar técnicas como sobremuestreo de la clase minoritaria o submuestreo de la clase mayoritaria.\n",
    "- **Ingeniería de características**: Desarrollar o seleccionar características más informativas específicas para identificar la agresividad.\n",
    "- **Ajuste de parámetros**: Continuar ajustando los parámetros del modelo SVM, posiblemente explorando más allá de los valores de `C` proporcionados.\n",
    "- **Evaluación con otras métricas**: Centrarse en métricas que sean más informativas para conjuntos de datos desequilibrados, como el área bajo la curva ROC (AUC-ROC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora vemos la lista de los ejemplos incorrectos\n",
    "\n",
    "incorrect = []\n",
    "\n",
    "for e in zip(val_labels, y_pred, range(len(val_labels))):\n",
    "    if e[0] != e[1]:\n",
    "        incorrect += [e[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto:  Al perro que se te acerque le parto su madre a si de facil\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  Por un mega-error escuché parte de una canción de banda y decia \"Demosle vuelo a la hilacha\" Que putas madres 😂😂 #PenaAjena\n",
      "Truth:  0\n",
      "Pred:  1\n",
      "Texto:  @USUARIO Q gusto m daria q Peru elimine a la Argentina y la concha d la perra mas puta d Argentina la madre d @USUARIO\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  @USUARIO Ya m tienen hasta la madre esos maes\n",
      "Truth:  0\n",
      "Pred:  1\n",
      "Texto:  Me caga esa gente a la que le mientas la madre y ni siquiera tienen la decencia de contestar. Putos, les dicen.\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  @USUARIO @USUARIO Lo peor es q uds siguen hablando de engañar al pueblo\" hijos de su puta madre, pinches políticos de mierda\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  Pero un día te voy a tapar el culo mientras te estoy lamiendo la pantunfla a ver si te da una embolia, hija de tu puta madre\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  #PorMiCamisetaYo mando a chingar a su reputisima madre al América,  Televisa y Tvazteca chinguen a su madre mil veces!\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  Por está madre me agarré a vergazos con el de la combi y no le pagué, el puto decía que ya no valen.\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  Por mi los dos chinguen a su madre aquí y en persona par de putos\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  Políticos pseudoaficiomados que sólo en finales hablan de beisbol pueden ir mucho a chingar a su madre. Y peor cuando opinan.\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  Chingas a tu madre vulgar ladrón y junto a ti todos los que te aplauden.\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  Ya nomas sienten que lo tienen asegurado a uno y se empiezan a tardar en Whatsapp las hijas de sus putas madres.\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  chinguen su madre putos chilenos de mierda, #México en el mundial y tu país basura lo verá por TV jajaja 😄\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  @USUARIO @USUARIO @USUARIO Ese conchadesumadre del Yerko, que ni siquiera le alcanza pa maricón, porque hay que ser hombre antes y a ese le alcanza pa la mitad apenas\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  Verga pendejo y eso t lo platico tu madre verdad jajajaja estúpido joto de closet\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  Ah qué poca madre aretes y pestañas al perro, que las usen sus pinches dueñas pars ver si se les quita lo ignorante. <URL>\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  @USUARIO Presidente Trump, chingas a tu madre\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  @USUARIO Anda a dialogar con tu madre que posiblemente es la única que le queda un poco de paciencia diputado de mierd@ Renuncia hdp\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  Le cambiaron al canal donde estaba el partido, chinguen a su madre  #MexicanDesmotherPalMundial\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  Y chingas a tu puta madre, si te llego a encontrar maricón de mierda no vas a valer ni 10 centavos y me vale verga si tienes familia puto.\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  Acosaron a la amiga de mi novio en el camión 😤 que vayan a acosar a sus putas madres hijos de la chingada.\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  @USUARIO @USUARIO @USUARIO @USUARIO @USUARIO Poca madre tienen enrique dice el PRI es pura transparencia puro robar a lo descarado y la gente de la cierra que se chinguen bola de ratas\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  @USUARIO Muchas gracias Q:.H:., pásale tú también a chingar a tu madre, T.:A.:F:. #MiércolesDeMentadas\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  @USUARIO @USUARIO 😂😂😂...este hijo de su asesina madre está idiota, enfermo, mariguano, alguien que lo bloquee en Twitter  por favor..\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  @USUARIO No tienen abuela madre vergüenza....\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  El Gobierno Federal acaba de inaugurar una nueva ruta para que vayas y chingues toda tu reputísima madre\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  Ticos putos y llorones jajajaja les sigue llorando que México siga siendo su padre, chinguen a su madre\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  Yo aquí pudiendo quererte bonito y tú haya quejándote de que nadie te quiere hijo de tu madre\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  Lo único bueno de regresar con tu ex novia es que ya sabes de que croquetas le gustan a la hija de su perra madre.\n",
      "Truth:  1\n",
      "Pred:  0\n"
     ]
    }
   ],
   "source": [
    "for e in incorrect:\n",
    "    case = e\n",
    "\n",
    "    if \"madre\" in val_text[case].strip():\n",
    "        print(\"Texto: \", val_text[case].strip())\n",
    "        print(\"Truth: \", val_labels[case])\n",
    "        print(\"Pred: \", y_pred[case])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PLN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
