{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pr√°ctica 3. Bolsas de palabras\n",
    "Guillermo Segura G√≥mez\n",
    "\n",
    "## MEX-A3T: Aggressiveness Analysis\n",
    "\n",
    "Vamos a utilizar un corpus llamado [MEX-A3T](https://sites.google.com/view/mex-a3t/home?authuser=0) que es un corpus creado en M√©xico. MEX-A3T es un corpus hecho para poder medir la agresividad y las fake news. El equipo de CIMAT se dedic√≥ al an√°lisis de identificaci√≥n de agresividad. \n",
    "\n",
    "Lo primero que es necesario hacer es leer los datos del corpus. El corpus incluye datos de entrenamiento asi como etiquetas.\n",
    "\n",
    "**Keras**\n",
    "\n",
    "Se introduce la liber√≠a **keras**. Keras es una biblioteca de Redes Neuronales de C√≥digo Abierto escrita en Python. Es capaz de ejecutarse sobre TensorFlow, Microsoft Cognitive Toolkit o Theano.\n",
    "\n",
    "Est√° especialmente dise√±ada para posibilitar la experimentaci√≥n en m√°s o menos poco tiempo con redes de Aprendizaje Profundo. Sus fuertes se centran en ser amigable para el usuario, modular y extensible.\n",
    "\n",
    "**Tensorflow**\n",
    "\n",
    "Adem√°s trabajaremos con la liber√≠a **tensorflow**. TensorFlow es una biblioteca de c√≥digo abierto para aprendizaje autom√°tico a trav√©s de un rango de tareas, y desarrollado por Google para satisfacer sus necesidades de sistemas capaces de construir y entrenar redes neuronales para detectar y descifrar patrones y correlaciones, an√°logos al aprendizaje y razonamiento usados por los humanos.\n",
    "\n",
    "**¬øQu√© es un tokenizador?**\n",
    "\n",
    "Recordando el concepto de tokenizador que realizamos en la pr√°ctica 2. Un tokenizador es una herramienta que se utiliza para dividir un texto en unidades m√°s peque√±as llamadas tokens. Estos tokens suelen ser palabras, pero tambi√©n pueden ser caracteres o subpalabras, dependiendo de c√≥mo se configure el tokenizador. El proceso de tokenizaci√≥n es un paso fundamental en muchas tareas de NLP, ya que permite convertir texto no estructurado en una forma que los modelos de machine learning pueden entender y procesar.\n",
    "\n",
    "Por ejemplo, la frase \"Me gusta programar en Python\" podr√≠a tokenizarse en los tokens [\"Me\", \"gusta\", \"programar\", \"en\", \"Python\"].\n",
    "\n",
    "**Tokenizador de Keras**\n",
    "\n",
    "El tokenizador `from keras.preprocessing.text import Tokenizer`, es una herramienta que viene con Keras. Este tokenizador realiza precisamente la tarea descrita anteriormente: divide el texto en tokens y puede convertir estos tokens en secuencias de n√∫meros, lo que los hace √∫tiles para entrenar modelos de deep learning.\n",
    "\n",
    "Sin embargo, este componente ahora forma parte de TensorFlow, bajo `tf.keras.preprocessing.text.Tokenizer`. Desde que TensorFlow absorbi√≥ Keras como su API de alto nivel, la mayor√≠a de las herramientas de Keras se acceden a trav√©s del m√≥dulo `tf.keras`.\n",
    "\n",
    "**Tokenizador de TensorFlow**\n",
    "\n",
    "El tokenizador que encontraste en TensorFlow (`tf.keras.preprocessing.text.Tokenizer`) funciona de manera muy similar al tokenizador original de Keras. Aqu√≠ tienes una descripci√≥n de los par√°metros que mencionaste:\n",
    "\n",
    "- `num_words`: El n√∫mero m√°ximo de palabras que se guardar√°n, basado en la frecuencia de palabra. Solo las `num_words` m√°s comunes ser√°n retenidas.\n",
    "- `filters`: Una cadena en la que cada elemento es un car√°cter que se filtrar√° del texto. Es decir, estos caracteres ser√°n ignorados durante la tokenizaci√≥n.\n",
    "- `lower`: Un booleano que indica si se debe convertir el texto a min√∫sculas.\n",
    "- `split`: El car√°cter que se utilizar√° como delimitador para dividir el texto en tokens.\n",
    "- `char_level`: Si es True, cada car√°cter ser√° tratado como un token.\n",
    "- `oov_token`: Un valor que se asignar√° a los tokens fuera del vocabulario (palabras que no se han visto durante el entrenamiento).\n",
    "- `analyzer`: Este par√°metro no est√° documentado en la versi√≥n est√°ndar de TensorFlow y podr√≠a no ser aplicable.\n",
    "\n",
    "Para utilizar este tokenizador, primero instancias el objeto `Tokenizer` con los par√°metros que desees y luego lo ajustas a tus textos utilizando el m√©todo `.fit_on_texts(texts)`. Despu√©s de ajustarlo, puedes usar `.texts_to_sequences(texts)` para convertir tus textos en secuencias de n√∫meros, que son los √≠ndices de los tokens en el vocabulario del tokenizador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 3, 4, 5, 1], [1, 6, 7, 8, 9, 10]]\n"
     ]
    }
   ],
   "source": [
    "# Instanciando el tokenizador\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=1000)\n",
    "\n",
    "# Ejemplo de texto\n",
    "texts = [\"Me gusta programar en Python\", \"Python es genial para machine learning\"]\n",
    "\n",
    "# Ajustando el tokenizador en los textos\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "# Convirtiendo textos a secuencias de tokens\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "print(sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora trabajaremos con los archivos del corpus MEX-A3T, necesitamos una funci√≥n que lea los archivos del corpus y nos regrese el texto en una lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_file(path_corpus, path_truth):\n",
    "\n",
    "    tr_text = []\n",
    "    tr_labels = []\n",
    "\n",
    "    with open(path_corpus, \"r\") as f_corpus, open(path_truth, \"r\") as f_truth:\n",
    "        for tweet in f_corpus:\n",
    "            tr_text += [tweet]\n",
    "        for label in f_truth:\n",
    "            tr_labels += [label]\n",
    "\n",
    "    return tr_text, tr_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_text = \"/Users/guillermo_sego/Desktop/Segundo Semestre/PLN/MexData/mex20_train.txt\"\n",
    "path_labels = \"/Users/guillermo_sego/Desktop/Segundo Semestre/PLN/MexData/mex20_train_labels.txt\"\n",
    "\n",
    "tr_text, tr_labels = get_text_from_file(path_text, path_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@USUARIO @USUARIO @USUARIO Q se puede esperar del maricon de closet de la Ya√±ez aun recuerdo esa ves q lo vi en zona rosa viendo quien lo levantada\\n',\n",
       " '@USUARIO La piel nueva siempre arde un poquito los primeros d√≠as... y m√°s con este puto clima\\n',\n",
       " 'Ustedes no se enamoran de m√≠‚Ä¶ por tontas.\\n',\n",
       " 'Me las va a pagar esa puta gorda roba tuits...\\n',\n",
       " '@USUARIO LA GENTE ES TONTA PORQUE NO SE DAN CUENTA QUE T√ö HACES A BATMAN AZUL\\n']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1\\n', '0\\n', '1\\n', '1\\n', '0\\n']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_labels[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El contenido de los arreglos es la informaci√≥n encontrada en el corpus de entrenamiento. En el arreglo **tr_text** encontramos el texto de los tweets, mientras que en el arreglo **tr_labels** est√° la etiqueta de si es agresivo o no es agresivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estad√≠sticas Simples\n",
    "\n",
    "Vamos a realizar una inspecci√≥n de los datos, esto con el prop√≥sito de observar cuantos datos hay. Podemos utilizar la liber√≠a matplotlib para este fin. Adem√°s utilizamos un contador de la librer√≠a counter. Vamos a contar las etiquetas del data set y construimos un histograma. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'0\\n': 3759, '1\\n': 1519})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Class')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "print(Counter(tr_labels))\n",
    "\n",
    "plt.hist(tr_labels, bins=len(set(tr_labels)))\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.xlabel(\"Class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay mas contenido que no es agresivo, mas del doble.\n",
    "\n",
    "## Construcci√≥n del vocabulario\n",
    "\n",
    "Ahora vamos a constuir el vocabulario utilizando el m√©todo de **TweetTokenizer** de la clase *tokenize* de la librer√≠a nltk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tokenizer = TweetTokenizer() # Inicializar tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_palabras = []\n",
    "\n",
    "for doc in tr_text:\n",
    "    corpus_palabras += tokenizer.tokenize(doc)\n",
    "\n",
    "fdist = nltk.FreqDist(corpus_palabras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El tama√±o del corpus es: 97473\n",
      "El tama√±o del vocabulario es: 15194\n"
     ]
    }
   ],
   "source": [
    "print(f\"El tama√±o del corpus es:\", len(corpus_palabras))\n",
    "print(f\"El tama√±o del vocabulario es:\", len(fdist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@USUARIO',\n",
       " '@USUARIO',\n",
       " '@USUARIO',\n",
       " 'Q',\n",
       " 'se',\n",
       " 'puede',\n",
       " 'esperar',\n",
       " 'del',\n",
       " 'maricon',\n",
       " 'de']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_palabras[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({',': 3016, 'de': 2915, 'que': 2829, '.': 2604, 'la': 2031, 'a': 1956, 'y': 1856, '!': 1435, 'no': 1430, '@USUARIO': 1399, ...})"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La construcci√≥n de la bolsa de palabras en esta pr√°ctica se realiza a mano. Existen algunas librerias de Machine Learning que realizan este proceso, sin embargo no permiten determinar el total de informaci√≥n, ya que se pierden algunos detalles en el procesamiento.\n",
    "\n",
    "Ahora necesitamos ordenar las frecuencias del vocabulario para poder trabajar con el."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  SortFrecuency(freqdist):\n",
    "    # List comprenhension\n",
    "    aux = [(freqdist[key], key) for key in freqdist]\n",
    "    aux.sort() # Ordena la lista\n",
    "    aux.reverse() # Cambiar el orden\n",
    "\n",
    "    return aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3016, ','), (2915, 'de'), (2829, 'que'), (2604, '.'), (2031, 'la')]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc = SortFrecuency(fdist)\n",
    "voc = voc[:5000]\n",
    "voc[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a trabajar √∫nicamente con los 5 mil t√©rminos mas comunes. Esto por simplicidad. Vamos a trabajar con un diccionario de python. Es bastante √∫til si podemos lograr tener la {palabra, valor} en donde el valor se refiere al √≠ndice de palabra o el lugar donde se encuentra, siendo 1 la palabra mas frecuente y 5000 la palabra menos frecuente, es decir estamos creando un diccionario que accesa a la palabra en funci√≥n de su lugar en el vector. Adem√°s el diccionario tiene un orden de acceso b√°stante r√°pido ya que es una tabla hash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{',': 0,\n",
       " 'de': 1,\n",
       " 'que': 2,\n",
       " '.': 3,\n",
       " 'la': 4,\n",
       " 'a': 5,\n",
       " 'y': 6,\n",
       " '!': 7,\n",
       " 'no': 8,\n",
       " '@USUARIO': 9,\n",
       " 'me': 10,\n",
       " 'el': 11,\n",
       " 'en': 12,\n",
       " 'se': 13,\n",
       " 'es': 14,\n",
       " 'con': 15,\n",
       " '?': 16,\n",
       " 'verga': 17,\n",
       " 'los': 18,\n",
       " 'madre': 19,\n",
       " 'por': 20,\n",
       " 'las': 21,\n",
       " '\"': 22,\n",
       " 'un': 23,\n",
       " 'te': 24,\n",
       " 'mi': 25,\n",
       " 'lo': 26,\n",
       " 'putas': 27,\n",
       " 'una': 28,\n",
       " '...': 29,\n",
       " 'putos': 30,\n",
       " 'para': 31,\n",
       " 'üòÇ': 32,\n",
       " 'si': 33,\n",
       " 'ya': 34,\n",
       " 'como': 35,\n",
       " 'su': 36,\n",
       " 'pero': 37,\n",
       " 'tu': 38,\n",
       " 'loca': 39,\n",
       " 'le': 40,\n",
       " 'm√°s': 41,\n",
       " 'No': 42,\n",
       " 'del': 43,\n",
       " 'gorda': 44,\n",
       " 'al': 45,\n",
       " 'bien': 46,\n",
       " 'A': 47,\n",
       " '¬ø': 48,\n",
       " 'Y': 49,\n",
       " 'son': 50,\n",
       " 'Me': 51,\n",
       " 'o': 52,\n",
       " 'feas': 53,\n",
       " 'cuando': 54,\n",
       " 'Que': 55,\n",
       " ':': 56,\n",
       " 'yo': 57,\n",
       " 'les': 58,\n",
       " 'porque': 59,\n",
       " 'ni': 60,\n",
       " 'est√°': 61,\n",
       " 'ser': 62,\n",
       " 'estoy': 63,\n",
       " 'sus': 64,\n",
       " 'todos': 65,\n",
       " 'esta': 66,\n",
       " 'puta': 67,\n",
       " 'Ya': 68,\n",
       " 'todo': 69,\n",
       " 'pinche': 70,\n",
       " 'puto': 71,\n",
       " 'tan': 72,\n",
       " 'Si': 73,\n",
       " 'La': 74,\n",
       " 'qu√©': 75,\n",
       " '‚Ä¶': 76,\n",
       " 'eso': 77,\n",
       " 'muy': 78,\n",
       " 'soy': 79,\n",
       " 'hasta': 80,\n",
       " 'as√≠': 81,\n",
       " '¬°': 82,\n",
       " '<URL>': 83,\n",
       " 'mamar': 84,\n",
       " 'hay': 85,\n",
       " 'q': 86,\n",
       " 'DE': 87,\n",
       " 'mis': 88,\n",
       " 'joto': 89,\n",
       " 'hace': 90,\n",
       " 'este': 91,\n",
       " 'cosas': 92,\n",
       " 'Ô∏è': 93,\n",
       " 'vida': 94,\n",
       " 'nos': 95,\n",
       " 'ver': 96,\n",
       " 'mejor': 97,\n",
       " 'solo': 98,\n",
       " 'nada': 99,\n",
       " 'vale': 100,\n",
       " 'va': 101,\n",
       " 'quiero': 102,\n",
       " 'marica': 103,\n",
       " 'eres': 104,\n",
       " 'd√≠a': 105,\n",
       " 'siempre': 106,\n",
       " 'esa': 107,\n",
       " 'voy': 108,\n",
       " 'gente': 109,\n",
       " 'Yo': 110,\n",
       " 'üò≠': 111,\n",
       " 'vez': 112,\n",
       " 'El': 113,\n",
       " 'mierda': 114,\n",
       " '-': 115,\n",
       " 'tengo': 116,\n",
       " '(': 117,\n",
       " 'sin': 118,\n",
       " 'ese': 119,\n",
       " ')': 120,\n",
       " 'Es': 121,\n",
       " 'luchona': 122,\n",
       " 'üòç': 123,\n",
       " 'hdp': 124,\n",
       " 'ahora': 125,\n",
       " 'Por': 126,\n",
       " 'üò°': 127,\n",
       " '‚Äú': 128,\n",
       " 'tienen': 129,\n",
       " 'tiene': 130,\n",
       " 'pinches': 131,\n",
       " 'hacer': 132,\n",
       " 'tus': 133,\n",
       " 'tontas': 134,\n",
       " 'LA': 135,\n",
       " '‚Äù': 136,\n",
       " 'gusta': 137,\n",
       " 'Como': 138,\n",
       " 'sea': 139,\n",
       " 'HDP': 140,\n",
       " 'toda': 141,\n",
       " 'Se': 142,\n",
       " 'hoy': 143,\n",
       " 'Qu√©': 144,\n",
       " 'mamando': 145,\n",
       " 'est√°n': 146,\n",
       " 'cagado': 147,\n",
       " 'tonta': 148,\n",
       " 'Pero': 149,\n",
       " 'puedo': 150,\n",
       " 'mas': 151,\n",
       " 'üôÑ': 152,\n",
       " 'pendejo': 153,\n",
       " 'hijo': 154,\n",
       " 'NO': 155,\n",
       " 'En': 156,\n",
       " 'Mi': 157,\n",
       " 'mal': 158,\n",
       " 'estar': 159,\n",
       " 'QUE': 160,\n",
       " '..': 161,\n",
       " 'Lo': 162,\n",
       " 'algo': 163,\n",
       " 'PUTOS': 164,\n",
       " 'tener': 165,\n",
       " 'alguien': 166,\n",
       " 'Putos': 167,\n",
       " 'verdad': 168,\n",
       " 'mujer': 169,\n",
       " 'cabrona': 170,\n",
       " 'tambi√©n': 171,\n",
       " 'da': 172,\n",
       " 'puede': 173,\n",
       " 'decir': 174,\n",
       " 'madres': 175,\n",
       " 'mujeres': 176,\n",
       " 'maricon': 177,\n",
       " 'vas': 178,\n",
       " 'mucho': 179,\n",
       " 'dos': 180,\n",
       " 'MADRE': 181,\n",
       " '‚ù§': 182,\n",
       " 'van': 183,\n",
       " 's√©': 184,\n",
       " 'Estoy': 185,\n",
       " 'Cuando': 186,\n",
       " ';': 187,\n",
       " 's√≠': 188,\n",
       " 'otra': 189,\n",
       " 'est√°s': 190,\n",
       " 'a√±os': 191,\n",
       " 'Verga': 192,\n",
       " 'PUTAS': 193,\n",
       " 'Las': 194,\n",
       " 'ir': 195,\n",
       " 'chingada': 196,\n",
       " \"'\": 197,\n",
       " 'veces': 198,\n",
       " 't√∫': 199,\n",
       " 'hijos': 200,\n",
       " 'De': 201,\n",
       " 'quiere': 202,\n",
       " 'quien': 203,\n",
       " 'pues': 204,\n",
       " 'jajaja': 205,\n",
       " 'VERGA': 206,\n",
       " 'Te': 207,\n",
       " '3': 208,\n",
       " 'mundo': 209,\n",
       " 'menos': 210,\n",
       " '2': 211,\n",
       " 'ü§î': 212,\n",
       " 'uno': 213,\n",
       " 'nunca': 214,\n",
       " 'era': 215,\n",
       " 'cada': 216,\n",
       " 'd√≠as': 217,\n",
       " 'dice': 218,\n",
       " 'M√©xico': 219,\n",
       " 'todas': 220,\n",
       " 'esos': 221,\n",
       " 'amor': 222,\n",
       " 'Una': 223,\n",
       " 'tanto': 224,\n",
       " 'mam√°': 225,\n",
       " 'ganas': 226,\n",
       " 'esas': 227,\n",
       " 'O': 228,\n",
       " 'üòí': 229,\n",
       " 'tienes': 230,\n",
       " 'tiempo': 231,\n",
       " 'fue': 232,\n",
       " 'cuenta': 233,\n",
       " 'ME': 234,\n",
       " 'Jajajaja': 235,\n",
       " 'pendeja': 236,\n",
       " 'estaba': 237,\n",
       " 'dicen': 238,\n",
       " 'Madre': 239,\n",
       " 'wey': 240,\n",
       " 'pedo': 241,\n",
       " 'neta': 242,\n",
       " 'esto': 243,\n",
       " 'ti': 244,\n",
       " 'siento': 245,\n",
       " 'ma√±ana': 246,\n",
       " 'igual': 247,\n",
       " 'he': 248,\n",
       " 'd': 249,\n",
       " 'camote': 250,\n",
       " 'Los': 251,\n",
       " 'veo': 252,\n",
       " 'personas': 253,\n",
       " 'pasa': 254,\n",
       " 'hacen': 255,\n",
       " 'ha': 256,\n",
       " 'donde': 257,\n",
       " 'digo': 258,\n",
       " 'Hoy': 259,\n",
       " '/': 260,\n",
       " 'v': 261,\n",
       " 'unas': 262,\n",
       " 'bueno': 263,\n",
       " ':(': 264,\n",
       " 'fotos': 265,\n",
       " 'cabr√≥n': 266,\n",
       " 'Ahora': 267,\n",
       " 'otro': 268,\n",
       " 'mismo': 269,\n",
       " 'cabron': 270,\n",
       " 'buena': 271,\n",
       " 'ah√≠': 272,\n",
       " 'trabajo': 273,\n",
       " 'sabe': 274,\n",
       " 'nadie': 275,\n",
       " 'estas': 276,\n",
       " 'desde': 277,\n",
       " 'amigos': 278,\n",
       " 'alv': 279,\n",
       " 'Pinche': 280,\n",
       " 'm√≠': 281,\n",
       " 'hombres': 282,\n",
       " 'foto': 283,\n",
       " 'culo': 284,\n",
       " 'casa': 285,\n",
       " 'ardida': 286,\n",
       " 'Jajaja': 287,\n",
       " '*': 288,\n",
       " 'üòà': 289,\n",
       " 've': 290,\n",
       " 'valer': 291,\n",
       " 'han': 292,\n",
       " 'fuera': 293,\n",
       " 'e': 294,\n",
       " 'chingar': 295,\n",
       " 'Pues': 296,\n",
       " 'Esta': 297,\n",
       " 'pendejos': 298,\n",
       " 'mames': 299,\n",
       " 'ella': 300,\n",
       " 'cara': 301,\n",
       " 'ü§£': 302,\n",
       " 's√≥lo': 303,\n",
       " 'mil': 304,\n",
       " 's√∫per': 305,\n",
       " 'rico': 306,\n",
       " 'noche': 307,\n",
       " 'mundial': 308,\n",
       " 'luego': 309,\n",
       " 'jajajaja': 310,\n",
       " 'fin': 311,\n",
       " 'estos': 312,\n",
       " 'encanta': 313,\n",
       " 'amigo': 314,\n",
       " 'Tu': 315,\n",
       " 'EL': 316,\n",
       " 'üò©': 317,\n",
       " 'üé∂': 318,\n",
       " 'ustedes': 319,\n",
       " 'semana': 320,\n",
       " 'quieren': 321,\n",
       " 'pueden': 322,\n",
       " 'mientras': 323,\n",
       " 'aqu√≠': 324,\n",
       " 'antes': 325,\n",
       " 'dan': 326,\n",
       " 'Para': 327,\n",
       " 'Porque': 328,\n",
       " 'Gracias': 329,\n",
       " 'persona': 330,\n",
       " 'jaja': 331,\n",
       " 'gay': 332,\n",
       " 'dinero': 333,\n",
       " 'dijo': 334,\n",
       " 'creo': 335,\n",
       " 'buen': 336,\n",
       " 'amo': 337,\n",
       " 'YA': 338,\n",
       " 'PUTA': 339,\n",
       " 'ven': 340,\n",
       " 'sabes': 341,\n",
       " 'novio': 342,\n",
       " 'dar': 343,\n",
       " 'creen': 344,\n",
       " 'chingo': 345,\n",
       " 'caga': 346,\n",
       " 'Un': 347,\n",
       " 'Est√°': 348,\n",
       " 'Con': 349,\n",
       " 'As√≠': 350,\n",
       " 'unos': 351,\n",
       " 'putita': 352,\n",
       " 'perra': 353,\n",
       " 'peor': 354,\n",
       " 'gata': 355,\n",
       " 'falta': 356,\n",
       " 'digan': 357,\n",
       " 'deja': 358,\n",
       " 'a√∫n': 359,\n",
       " 'amiga': 360,\n",
       " 'Soy': 361,\n",
       " 'Putas': 362,\n",
       " 'EN': 363,\n",
       " '4': 364,\n",
       " '1': 365,\n",
       " 'üò†': 366,\n",
       " 'triste': 367,\n",
       " 'puedes': 368,\n",
       " 'mamen': 369,\n",
       " 'horas': 370,\n",
       " 'hablar': 371,\n",
       " 'entiendo': 372,\n",
       " 'dejar': 373,\n",
       " 'sean': 374,\n",
       " 'saben': 375,\n",
       " 'qui√©n': 376,\n",
       " 'pelan': 377,\n",
       " 'pa√≠s': 378,\n",
       " 'novia': 379,\n",
       " 'hora': 380,\n",
       " 'haciendo': 381,\n",
       " 'dormir': 382,\n",
       " 'despu√©s': 383,\n",
       " 'andar': 384,\n",
       " 'Ni': 385,\n",
       " '5': 386,\n",
       " 'üá≤üáΩ': 387,\n",
       " 'viendo': 388,\n",
       " 'vamos': 389,\n",
       " 'tarea': 390,\n",
       " 'tal': 391,\n",
       " 'prieta': 392,\n",
       " 'mamadas': 393,\n",
       " 'gusto': 394,\n",
       " 'cosa': 395,\n",
       " 'asi': 396,\n",
       " 'asco': 397,\n",
       " 'Ojal√°': 398,\n",
       " 'Hay': 399,\n",
       " 'üò§': 400,\n",
       " 'üòò': 401,\n",
       " 'vali√≥': 402,\n",
       " 'se√±ora': 403,\n",
       " 'saber': 404,\n",
       " 'rica': 405,\n",
       " 'palabra': 406,\n",
       " 'nalgas': 407,\n",
       " 'maric√≥n': 408,\n",
       " 'hago': 409,\n",
       " 'hab√≠a': 410,\n",
       " 'ellos': 411,\n",
       " 'c√≥mo': 412,\n",
       " 'boca': 413,\n",
       " 'SU': 414,\n",
       " 'LOS': 415,\n",
       " '#MasterChefMx': 416,\n",
       " 'üòè': 417,\n",
       " 'poca': 418,\n",
       " 'perro': 419,\n",
       " 'mandar': 420,\n",
       " 'llorar': 421,\n",
       " 'hombre': 422,\n",
       " 'chingas': 423,\n",
       " 'a√±o': 424,\n",
       " 'Todos': 425,\n",
       " 'Tengo': 426,\n",
       " 'Pinches': 427,\n",
       " 'üòå': 428,\n",
       " 'üíî': 429,\n",
       " 'üçÜ': 430,\n",
       " '√©l': 431,\n",
       " 'vergas': 432,\n",
       " 'sigue': 433,\n",
       " 'risa': 434,\n",
       " 're': 435,\n",
       " 'quieres': 436,\n",
       " 'queda': 437,\n",
       " 'puro': 438,\n",
       " 'ponen': 439,\n",
       " 'pone': 440,\n",
       " 'otras': 441,\n",
       " 'odio': 442,\n",
       " 'misma': 443,\n",
       " 'miedo': 444,\n",
       " 'iba': 445,\n",
       " 'hubiera': 446,\n",
       " 'golfa': 447,\n",
       " 'ex': 448,\n",
       " 'dejen': 449,\n",
       " 'debe': 450,\n",
       " 'bonito': 451,\n",
       " 'PARA': 452,\n",
       " 'siguen': 453,\n",
       " 'pobre': 454,\n",
       " 'parte': 455,\n",
       " 'importa': 456,\n",
       " 'hizo': 457,\n",
       " 'hija': 458,\n",
       " 'feo': 459,\n",
       " 'feliz': 460,\n",
       " 'fea': 461,\n",
       " 'favor': 462,\n",
       " 'culpa': 463,\n",
       " 'Quiero': 464,\n",
       " 'Este': 465,\n",
       " 'Alguien': 466,\n",
       " '10': 467,\n",
       " 'üî•': 468,\n",
       " 'vieja': 469,\n",
       " 'valiendo': 470,\n",
       " 'tarde': 471,\n",
       " 'seguro': 472,\n",
       " 'salir': 473,\n",
       " 'pu√±al': 474,\n",
       " 'poner': 475,\n",
       " 'pensar': 476,\n",
       " 'partido': 477,\n",
       " 'minutos': 478,\n",
       " 'lugar': 479,\n",
       " 'llega': 480,\n",
       " 'diga': 481,\n",
       " 'chinga': 482,\n",
       " 'canci√≥n': 483,\n",
       " 'ando': 484,\n",
       " 'anda': 485,\n",
       " 'RT': 486,\n",
       " 'PUTO': 487,\n",
       " 'Eso': 488,\n",
       " '$': 489,\n",
       " 'üôÉ': 490,\n",
       " 'üòû': 491,\n",
       " 'üòî': 492,\n",
       " 'somos': 493,\n",
       " 'sido': 494,\n",
       " 'pena': 495,\n",
       " 'parece': 496,\n",
       " 'momento': 497,\n",
       " 'mando': 498,\n",
       " 'lameculos': 499,\n",
       " 'huevos': 500,\n",
       " 'hermano': 501,\n",
       " 'familia': 502,\n",
       " 'entre': 503,\n",
       " 'contigo': 504,\n",
       " 'bonita': 505,\n",
       " 'agua': 506,\n",
       " 'acabo': 507,\n",
       " 'Siempre': 508,\n",
       " 'Neta': 509,\n",
       " 'Les': 510,\n",
       " 'Le': 511,\n",
       " 'Hasta': 512,\n",
       " 'ES': 513,\n",
       " 'ü§¶üèª\\u200d‚ôÄ': 514,\n",
       " 'üòé': 515,\n",
       " 'üí¶': 516,\n",
       " '|': 517,\n",
       " 'volver': 518,\n",
       " 'visto': 519,\n",
       " 'viejas': 520,\n",
       " 'ves': 521,\n",
       " 'valen': 522,\n",
       " 'sobre': 523,\n",
       " 'servicio': 524,\n",
       " 'seas': 525,\n",
       " 'sale': 526,\n",
       " 'primera': 527,\n",
       " 'pongo': 528,\n",
       " 'poder': 529,\n",
       " 'perros': 530,\n",
       " 'pasan': 531,\n",
       " 'pasado': 532,\n",
       " 'nuevo': 533,\n",
       " 'mama': 534,\n",
       " 'lado': 535,\n",
       " 'fui': 536,\n",
       " 'forma': 537,\n",
       " 'escuela': 538,\n",
       " 'escuchar': 539,\n",
       " 'dije': 540,\n",
       " 'dicho': 541,\n",
       " 'dices': 542,\n",
       " 'conmigo': 543,\n",
       " 'Twitter': 544,\n",
       " 'TU': 545,\n",
       " 'Solo': 546,\n",
       " 'SE': 547,\n",
       " 'Jajajajaja': 548,\n",
       " 'Gorda': 549,\n",
       " 'Dios': 550,\n",
       " 'C√≥mo': 551,\n",
       " 'Creo': 552,\n",
       " 'Ay': 553,\n",
       " 'Aqu√≠': 554,\n",
       " 'Ah': 555,\n",
       " '7': 556,\n",
       " '20': 557,\n",
       " 'üò±': 558,\n",
       " 'vista': 559,\n",
       " 'video': 560,\n",
       " 'valgo': 561,\n",
       " 'tanta': 562,\n",
       " 'sigo': 563,\n",
       " 'ser√°': 564,\n",
       " 'rato': 565,\n",
       " 'problema': 566,\n",
       " 'pa': 567,\n",
       " 'otros': 568,\n",
       " 'm√∫sica': 569,\n",
       " 'llevo': 570,\n",
       " 'lleva': 571,\n",
       " 'jajajajaja': 572,\n",
       " 'hecho': 573,\n",
       " 'haga': 574,\n",
       " 'haber': 575,\n",
       " 'grande': 576,\n",
       " 'gracias': 577,\n",
       " 'entonces': 578,\n",
       " 'doy': 579,\n",
       " 'diciendo': 580,\n",
       " 'chiflar': 581,\n",
       " 'cagan': 582,\n",
       " 'buenas': 583,\n",
       " 'andan': 584,\n",
       " 'amigas': 585,\n",
       " 'V': 586,\n",
       " 'Su': 587,\n",
       " 'POR': 588,\n",
       " 'PINCHE': 589,\n",
       " 'LOCA': 590,\n",
       " 'JAJAJA': 591,\n",
       " 'üôä': 592,\n",
       " 'üò£': 593,\n",
       " '‚òπ': 594,\n",
       " '√∫nico': 595,\n",
       " 'xD': 596,\n",
       " 'vi': 597,\n",
       " 'tres': 598,\n",
       " 'trabajar': 599,\n",
       " 'siendo': 600,\n",
       " 'seguir': 601,\n",
       " 'quiera': 602,\n",
       " 'quer√≠a': 603,\n",
       " 'primero': 604,\n",
       " 'pap√°': 605,\n",
       " 'padre': 606,\n",
       " 'ojal√°': 607,\n",
       " 'ni√±o': 608,\n",
       " 'ni√±as': 609,\n",
       " 'ni√±a': 610,\n",
       " 'meter': 611,\n",
       " 'hablando': 612,\n",
       " 'final': 613,\n",
       " 'estamos': 614,\n",
       " 'dem√°s': 615,\n",
       " 'das': 616,\n",
       " 'comer': 617,\n",
       " 'clase': 618,\n",
       " 'caso': 619,\n",
       " 'casi': 620,\n",
       " 'UN': 621,\n",
       " 'TE': 622,\n",
       " 'Mis': 623,\n",
       " 'Marica': 624,\n",
       " 'LO': 625,\n",
       " 'LAS': 626,\n",
       " 'Eres': 627,\n",
       " 'COMO': 628,\n",
       " 'üò¨': 629,\n",
       " 'üò¢': 630,\n",
       " 'üòä': 631,\n",
       " 'üòÅ': 632,\n",
       " 'viejo': 633,\n",
       " 'tipo': 634,\n",
       " 'sola': 635,\n",
       " 'respeto': 636,\n",
       " 'raz√≥n': 637,\n",
       " 'pasar': 638,\n",
       " 'palabras': 639,\n",
       " 'pagar': 640,\n",
       " 'nombre': 641,\n",
       " 'noches': 642,\n",
       " 'medio': 643,\n",
       " 'mano': 644,\n",
       " 'llama': 645,\n",
       " 'huevo': 646,\n",
       " 'hambre': 647,\n",
       " 'haces': 648,\n",
       " 'esperando': 649,\n",
       " 'equipo': 650,\n",
       " 'cualquier': 651,\n",
       " 'creer': 652,\n",
       " 'chinguen': 653,\n",
       " 'chica': 654,\n",
       " 'celular': 655,\n",
       " 'calle': 656,\n",
       " 'aunque': 657,\n",
       " 'ardidas': 658,\n",
       " 'S√≠': 659,\n",
       " 'Quien': 660,\n",
       " 'Puto': 661,\n",
       " 'Mira': 662,\n",
       " 'Ma√±ana': 663,\n",
       " 'Esa': 664,\n",
       " 'Al': 665,\n",
       " '6': 666,\n",
       " '&': 667,\n",
       " 'ü§§': 668,\n",
       " 'üòú': 669,\n",
       " 'vos': 670,\n",
       " 'videos': 671,\n",
       " 'vaya': 672,\n",
       " 'ten√≠a': 673,\n",
       " 'siente': 674,\n",
       " 'punto': 675,\n",
       " 'porqu√©': 676,\n",
       " 'poco': 677,\n",
       " 'paso': 678,\n",
       " 'partir': 679,\n",
       " 'parecen': 680,\n",
       " 'ojos': 681,\n",
       " 'nosotros': 682,\n",
       " 'maldito': 683,\n",
       " 'lluvia': 684,\n",
       " 'hice': 685,\n",
       " 'gordas': 686,\n",
       " 'estan': 687,\n",
       " 'estado': 688,\n",
       " 'eran': 689,\n",
       " 'ellas': 690,\n",
       " 'd√≥nde': 691,\n",
       " 'den': 692,\n",
       " 'deber√≠an': 693,\n",
       " 'culero': 694,\n",
       " 'coraz√≥n': 695,\n",
       " 'clases': 696,\n",
       " 'cargo': 697,\n",
       " 'cae': 698,\n",
       " 'ayer': 699,\n",
       " 'adem√°s': 700,\n",
       " 'Todo': 701,\n",
       " 'Teresa': 702,\n",
       " 'TODOS': 703,\n",
       " 'SI': 704,\n",
       " 'Puta': 705,\n",
       " 'Jajajajajaja': 706,\n",
       " 'HIJO': 707,\n",
       " 'CON': 708,\n",
       " '@': 709,\n",
       " 'üò™': 710,\n",
       " 'üòï': 711,\n",
       " 'üòã': 712,\n",
       " 'x': 713,\n",
       " 'vuelve': 714,\n",
       " 'viene': 715,\n",
       " 'usar': 716,\n",
       " 'tengan': 717,\n",
       " 'tenemos': 718,\n",
       " 'tambien': 719,\n",
       " 'tacos': 720,\n",
       " 'sue√±o': 721,\n",
       " 'serio': 722,\n",
       " 'salen': 723,\n",
       " 'sabemos': 724,\n",
       " 'pura': 725,\n",
       " 'pueblo': 726,\n",
       " 'poniendo': 727,\n",
       " 'pol√≠ticos': 728,\n",
       " 'pienso': 729,\n",
       " 'periodistas': 730,\n",
       " 'pendejas': 731,\n",
       " 'nivel': 732,\n",
       " 'meses': 733,\n",
       " 'mes': 734,\n",
       " 'mariquita': 735,\n",
       " 'lleno': 736,\n",
       " 'llegar': 737,\n",
       " 'juego': 738,\n",
       " 'historia': 739,\n",
       " 'hermoso': 740,\n",
       " 'hagan': 741,\n",
       " 'grupo': 742,\n",
       " 'fan': 743,\n",
       " 'espero': 744,\n",
       " 'escribir': 745,\n",
       " 'dio': 746,\n",
       " 'demasiado': 747,\n",
       " 'deje': 748,\n",
       " 'dado': 749,\n",
       " 'contra': 750,\n",
       " 'arruga': 751,\n",
       " 'Wey': 752,\n",
       " 'Son': 753,\n",
       " 'Qui√©n': 754,\n",
       " 'HIJOS': 755,\n",
       " 'Chinga': 756,\n",
       " 'ALV': 757,\n",
       " 'üôà': 758,\n",
       " 'üòª': 759,\n",
       " 'üòÖ': 760,\n",
       " 'üíï': 761,\n",
       " 'volviendo': 762,\n",
       " 'vato': 763,\n",
       " 'tuits': 764,\n",
       " 'tenga': 765,\n",
       " 'sali√≥': 766,\n",
       " 'putito': 767,\n",
       " 'primer': 768,\n",
       " 'pones': 769,\n",
       " 'pesos': 770,\n",
       " 'pela': 771,\n",
       " 'partidos': 772,\n",
       " 'nuestros': 773,\n",
       " 'nuestro': 774,\n",
       " 'necesito': 775,\n",
       " 'muchas': 776,\n",
       " 'morra': 777,\n",
       " 'moral': 778,\n",
       " 'mayor': 779,\n",
       " 'matar': 780,\n",
       " 'manos': 781,\n",
       " 'mamo': 782,\n",
       " 'mamaste': 783,\n",
       " 'maldita': 784,\n",
       " 'mala': 785,\n",
       " 'leche': 786,\n",
       " 'lados': 787,\n",
       " 'hermosa': 788,\n",
       " 'has': 789,\n",
       " 'gran': 790,\n",
       " 'golfas': 791,\n",
       " 'f√∫tbol': 792,\n",
       " 'fueron': 793,\n",
       " 'fr√≠o': 794,\n",
       " 'diario': 795,\n",
       " 'dejan': 796,\n",
       " 'darle': 797,\n",
       " 'dando': 798,\n",
       " 'costumbre': 799,\n",
       " 'cierto': 800,\n",
       " 'chingue': 801,\n",
       " 'cabeza': 802,\n",
       " 'buenos': 803,\n",
       " 'bola': 804,\n",
       " 'ba√±o': 805,\n",
       " 'acabar': 806,\n",
       " 'Vale': 807,\n",
       " 'T√∫': 808,\n",
       " 'SUS': 809,\n",
       " 'Mam√°': 810,\n",
       " 'MI': 811,\n",
       " 'Jaja': 812,\n",
       " 'Esos': 813,\n",
       " 'Esas': 814,\n",
       " 'Desde': 815,\n",
       " 'Bueno': 816,\n",
       " '>': 817,\n",
       " 'ü§∑üèª\\u200d‚ôÄ': 818,\n",
       " 'ü§ó': 819,\n",
       " 'üòë': 820,\n",
       " 'üòâ': 821,\n",
       " 'üëè': 822,\n",
       " 'xq': 823,\n",
       " 'we': 824,\n",
       " 'vivo': 825,\n",
       " 'vayan': 826,\n",
       " 'tuve': 827,\n",
       " 'tristes': 828,\n",
       " 'tantos': 829,\n",
       " 'tantas': 830,\n",
       " 'suerte': 831,\n",
       " 'siquiera': 832,\n",
       " 'sienten': 833,\n",
       " 'saca': 834,\n",
       " 'ropa': 835,\n",
       " 'puras': 836,\n",
       " 'perder': 837,\n",
       " 'pens√©': 838,\n",
       " 'paz': 839,\n",
       " 'pase': 840,\n",
       " 'nueva': 841,\n",
       " 'ni√±os': 842,\n",
       " 'ning√∫n': 843,\n",
       " 'mandan': 844,\n",
       " 'mam√≥': 845,\n",
       " 'mamada': 846,\n",
       " 'llorando': 847,\n",
       " 'jugar': 848,\n",
       " 'jam√°s': 849,\n",
       " 'hondure√±os': 850,\n",
       " 'hermana': 851,\n",
       " 'habla': 852,\n",
       " 'gustan': 853,\n",
       " 'gobierno': 854,\n",
       " 'frase': 855,\n",
       " 'examen': 856,\n",
       " 'empieza': 857,\n",
       " 'dijeron': 858,\n",
       " 'darme': 859,\n",
       " 'cual': 860,\n",
       " 'comiendo': 861,\n",
       " 'chile': 862,\n",
       " 'caracteres': 863,\n",
       " 'cagada': 864,\n",
       " 'bonitas': 865,\n",
       " 'Sabes': 866,\n",
       " 'Q': 867,\n",
       " 'Nunca': 868,\n",
       " 'Nada': 869,\n",
       " 'M√°s': 870,\n",
       " 'Messi': 871,\n",
       " 'Esto': 872,\n",
       " 'Ese': 873,\n",
       " 'DEL': 874,\n",
       " 'Chingas': 875,\n",
       " 'Chile': 876,\n",
       " 'Cada': 877,\n",
       " 'Amo': 878,\n",
       " '8': 879,\n",
       " 'üòñ': 880,\n",
       " 'üòê': 881,\n",
       " 'üíñ': 882,\n",
       " 'üëå': 883,\n",
       " '‚ò∫': 884,\n",
       " 'v√°yanse': 885,\n",
       " 'vuelven': 886,\n",
       " 'vivir': 887,\n",
       " 'venir': 888,\n",
       " 'vemos': 889,\n",
       " 'valga': 890,\n",
       " 'usan': 891,\n",
       " 'tweets': 892,\n",
       " 'trae': 893,\n",
       " 'todav√≠a': 894,\n",
       " 'temprano': 895,\n",
       " 'sigues': 896,\n",
       " 'ser√≠a': 897,\n",
       " 'seria': 898,\n",
       " 'salgo': 899,\n",
       " 'querer': 900,\n",
       " 'prietas': 901,\n",
       " 'peda': 902,\n",
       " 'pas√≥': 903,\n",
       " 'normal': 904,\n",
       " 'naturaleza': 905,\n",
       " 'm√≠a': 906,\n",
       " 'mucha': 907,\n",
       " 'mira': 908,\n",
       " 'mente': 909,\n",
       " 'mentada': 910,\n",
       " 'juntos': 911,\n",
       " 'ja': 912,\n",
       " 'imagen': 913,\n",
       " 'horrible': 914,\n",
       " 'haya': 915,\n",
       " 'hacerlo': 916,\n",
       " 'hablas': 917,\n",
       " 'hablan': 918,\n",
       " 'gringos': 919,\n",
       " 'gatos': 920,\n",
       " 'fuerte': 921,\n",
       " 'extra√±o': 922,\n",
       " 'etc': 923,\n",
       " 'est√©': 924,\n",
       " 'estar√≠a': 925,\n",
       " 'esperar': 926,\n",
       " 'empiezan': 927,\n",
       " 'edad': 928,\n",
       " 'duele': 929,\n",
       " 'diferente': 930,\n",
       " 'dieron': 931,\n",
       " 'derechos': 932,\n",
       " 'dentro': 933,\n",
       " 'cuerpo': 934,\n",
       " 'critican': 935,\n",
       " 'cree': 936,\n",
       " 'clima': 937,\n",
       " 'claro': 938,\n",
       " 'carro': 939,\n",
       " 'cagas': 940,\n",
       " 'ayuda': 941,\n",
       " 'am': 942,\n",
       " 'alg√∫n': 943,\n",
       " 'alguna': 944,\n",
       " 'alcohol': 945,\n",
       " 'acaba': 946,\n",
       " 'UNA': 947,\n",
       " 'Todas': 948,\n",
       " 'Tambi√©n': 949,\n",
       " 'S√≥lo': 950,\n",
       " 'Nos': 951,\n",
       " 'Mejor': 952,\n",
       " 'Loca': 953,\n",
       " 'Gente': 954,\n",
       " 'Facebook': 955,\n",
       " 'Est√°n': 956,\n",
       " 'Cosas': 957,\n",
       " 'Calcuta': 958,\n",
       " 'Buenos': 959,\n",
       " 'Ando': 960,\n",
       " '280': 961,\n",
       " 'ü§¶üèª\\u200d‚ôÇ': 962,\n",
       " 'üôÇ': 963,\n",
       " 'üòì': 964,\n",
       " 'üê∑': 965,\n",
       " 'üéµ': 966,\n",
       " '‚úäüèº': 967,\n",
       " '‚Äî': 968,\n",
       " '√∫nica': 969,\n",
       " 'verg√ºenza': 970,\n",
       " 'vergazos': 971,\n",
       " 'tr√°fico': 972,\n",
       " 'tobog√°n': 973,\n",
       " 'tel√©fono': 974,\n",
       " 't': 975,\n",
       " 'super': 976,\n",
       " 'subir': 977,\n",
       " 'sigan': 978,\n",
       " 'se√±or': 979,\n",
       " 'sexo': 980,\n",
       " 'sentir': 981,\n",
       " 'sentido': 982,\n",
       " 'selecci√≥n': 983,\n",
       " 'sab√≠a': 984,\n",
       " 'regreso': 985,\n",
       " 'realidad': 986,\n",
       " 'rateros': 987,\n",
       " 'queriendo': 988,\n",
       " 'puso': 989,\n",
       " 'puse': 990,\n",
       " 'puesto': 991,\n",
       " 'presidente': 992,\n",
       " 'porno': 993,\n",
       " 'ponerme': 994,\n",
       " 'placer': 995,\n",
       " 'piensan': 996,\n",
       " 'piel': 997,\n",
       " 'pesar': 998,\n",
       " 'pensando': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_indices = dict()\n",
    "count = 0\n",
    "\n",
    "for weight, word in voc:\n",
    "    dict_indices[word] = count\n",
    "    count += 1\n",
    "\n",
    "dict_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bow con scikit\n",
    "\n",
    "La bolsa de palabras es un modelo que simplifica el contenido textual al considerar solo la ocurrencia de palabras, ignorando su orden y contexto. En este modelo, un texto se representa como un vector, donde cada dimensi√≥n corresponde a una palabra del vocabulario de todos los textos considerados, y el valor en cada dimensi√≥n cuenta la frecuencia de esa palabra en el texto.\n",
    "\n",
    "Para construir una bolsa de palabras en `scikit-learn`, se puede usar la clase `CountVectorizer`:\n",
    "\n",
    "1. **Importar `CountVectorizer`**: Primero, es necesario importar la clase `CountVectorizer` de `sklearn.feature_extraction.text`.\n",
    "\n",
    "2. **Instanciar `CountVectorizer`**: Luego, se crea una instancia de `CountVectorizer`. Se puede personalizar varios par√°metros, como `max_features` para limitar el n√∫mero de palabras en el vocabulario, `stop_words` para excluir palabras comunes que no aportan mucho significado (como \"y\", \"o\", \"el\", etc.), y `ngram_range` para considerar combinaciones de palabras adem√°s de palabras individuales.\n",
    "\n",
    "3. **Ajustar el modelo**: Se ajusta el vectorizador a los documentos de texto con el m√©todo `.fit()`, lo que hace que el modelo aprenda el vocabulario.\n",
    "\n",
    "4. **Transformar textos**: Finalmente, se transforman los documentos de texto en vectores BoW utilizando el m√©todo `.transform()`. Esto convierte cada texto en un vector num√©rico donde cada elemento representa la frecuencia de una palabra del vocabulario en el texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario: ['aprendizaje' 'autom√°tico' 'del' 'el' 'es' 'facilita' 'fascinante'\n",
      " 'learn' 'learning' 'lenguaje' 'machine' 'natural' 'parte' 'procesamiento'\n",
      " 'scikit' 'una']\n",
      "Bolsa de palabras:\n",
      " [[1 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1]\n",
      " [0 0 0 1 0 1 0 1 1 0 1 0 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Ejemplo de documentos\n",
    "documentos = [\n",
    "    \"El aprendizaje autom√°tico es fascinante\",\n",
    "    \"El procesamiento de lenguaje natural es una parte del aprendizaje autom√°tico\",\n",
    "    \"Scikit-learn facilita el machine learning\"\n",
    "]\n",
    "\n",
    "# Instanciar CountVectorizer\n",
    "vectorizador = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Ajustar el modelo y transformar los documentos en una bolsa de palabras\n",
    "bolsa_de_palabras = vectorizador.fit_transform(documentos)\n",
    "\n",
    "# Convertir la bolsa de palabras a un array para visualizarla\n",
    "array_bolsa_de_palabras = bolsa_de_palabras.toarray()\n",
    "\n",
    "# Obtener el vocabulario\n",
    "vocabulario = vectorizador.get_feature_names_out()\n",
    "\n",
    "print(\"Vocabulario:\", vocabulario)\n",
    "print(\"Bolsa de palabras:\\n\", array_bolsa_de_palabras)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bolsa de t√©rminos\n",
    "\n",
    "Con la variable **dict_indices** ya podemos crear la bolsa de palabras. Utilizamos la librer√≠a numpy para trabajar con vectores. Construimos la bolsa de palabras en una matriz. La bolsa de palabras que construimos tiene un pesado binario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def build_bow_tr(tr_text, vocabulary, dict_indices):\n",
    "\n",
    "    # Construcci√≥n de matriz para la bolsa de palabras\n",
    "    # En cada fila vemos los documentos que estamos procesando\n",
    "    # En las columnas el tama√±o del vocabulario que estamos creando\n",
    "    BOW = np.zeros((len(tr_text),len(vocabulary)), dtype = int)\n",
    "\n",
    "    for tr in tr_text:\n",
    "        # Cada documento tr lo tokenizamos\n",
    "        fdist_doc = nltk.FreqDist(tokenizer.tokenize(tr))\n",
    "\n",
    "        # Definimos el contador para cada documento\n",
    "        cont_doc = 0\n",
    "\n",
    "        # Contamos cada palabra\n",
    "        for word in fdist_doc:\n",
    "\n",
    "            # Nos aseguramos que las palabras estan en el diccionario final de 5mil palabras\n",
    "            if word in dict_indices:\n",
    "                BOW[cont_doc, dict_indices[word]] = 1\n",
    "\n",
    "        cont_doc += 1\n",
    "\n",
    "    return BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 1, 1, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BOW_tr = build_bow_tr(tr_text, voc, dict_indices)\n",
    "BOW_tr[:10][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5278, 5000)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BOW_tr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bolsa de palabras de validaci√≥n\n",
    "\n",
    "Ahora construimos la bolsa de palabras para los t√©rminos de validaci√≥n. Utilizamos el mismo vocabulario y el mismo diccionario que ya construimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 418, 1: 169})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Class')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cargar los archivos de validaci√≥n\n",
    "\n",
    "path_text = \"/Users/guillermo_sego/Desktop/Segundo Semestre/PLN/MexData/mex20_val.txt\"\n",
    "path_labels = \"/Users/guillermo_sego/Desktop/Segundo Semestre/PLN/MexData/mex20_val_labels.txt\"\n",
    "\n",
    "val_text, val_labels = get_text_from_file(path_text, path_labels)\n",
    "\n",
    "# Hacemos una lista de enteros\n",
    "val_labels = list(map(int, val_labels))\n",
    "\n",
    "print(Counter(val_labels))\n",
    "\n",
    "plt.hist(val_labels, bins=len(set(val_labels)))\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.xlabel(\"Class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOW_val = build_bow_tr(val_text, voc, dict_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificaci√≥n\n",
    "\n",
    "Un clasificador es un algoritmo que se utiliza en machine learning para asignar una categor√≠a o clase a una instancia de datos bas√°ndose en sus caracter√≠sticas. Los clasificadores se entrenan con un conjunto de datos que ya tiene etiquetas de clase conocidas, en un proceso llamado aprendizaje supervisado. Una vez entrenado, el clasificador puede usarse para predecir la clase de nuevas instancias de datos.\n",
    "\n",
    "**Clasificador SVM (M√°quinas de Vectores de Soporte)**\n",
    "\n",
    "El clasificador SVM (Support Vector Machine, o M√°quinas de Vectores de Soporte en espa√±ol) es un algoritmo muy popular y potente en el campo del aprendizaje autom√°tico. Se utiliza principalmente para problemas de clasificaci√≥n, pero tambi√©n puede adaptarse para la regresi√≥n.\n",
    "\n",
    "El objetivo principal de un SVM es encontrar el hiperplano √≥ptimo (en 2D ser√≠a una l√≠nea, en 3D un plano, y as√≠ sucesivamente para dimensiones m√°s altas) que separe las clases de datos con el margen m√°s amplio posible. Este hiperplano se define como el que tiene la mayor distancia a los puntos de datos m√°s cercanos de cada clase, conocidos como vectores de soporte.\n",
    "\n",
    "**Funcionamiento B√°sico del SVM**\n",
    "\n",
    "- **Margen y Vectores de Soporte**: El SVM intenta maximizar el margen entre las clases. Los vectores de soporte son los puntos de datos m√°s cercanos al hiperplano de decisi√≥n, y el margen es la distancia entre estos puntos y el hiperplano. Un margen m√°s amplio ofrece mejor generalizaci√≥n, lo que significa que el clasificador tiene mejor capacidad para clasificar correctamente nuevos datos no vistos durante el entrenamiento.\n",
    "\n",
    "- **Kernel Trick**: Una de las caracter√≠sticas m√°s poderosas del SVM es su capacidad para operar en espacios de caracter√≠sticas de alta dimensi√≥n utilizando funciones kernel. Esto permite al SVM manejar datos que no son linealmente separables en su espacio original, transform√°ndolos a un espacio de mayor dimensi√≥n donde s√≠ lo son. Los kernels m√°s comunes incluyen el lineal, polinomial, y el de base radial (RBF).\n",
    "\n",
    "- **Problemas de Clasificaci√≥n y Regresi√≥n**: Aunque SVM se utiliza principalmente para la clasificaci√≥n, se puede adaptar para la regresi√≥n (SVR o Support Vector Regression).\n",
    "\n",
    "**Ejemplo de Uso del SVM en Scikit-learn**\n",
    "\n",
    "Este c√≥digo carga el conjunto de datos Iris, filtra para quedarse con dos clases para un problema binario, divide los datos en conjuntos de entrenamiento y prueba, los escala (un paso importante para los algoritmos basados en distancia como SVM), y luego entrena y eval√∫a un clasificador SVM con un kernel lineal.\n",
    "\n",
    "Los clasificadores, incluido el SVM, son herramientas esenciales en machine learning y tienen una amplia gama de aplicaciones, desde reconocimiento de im√°genes y voz hasta clasificaci√≥n de textos y m√°s all√°."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisi√≥n del clasificador SVM: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Cargar un conjunto de datos de ejemplo\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Para simplificar, nos quedamos solo con dos clases\n",
    "X = X[y != 2]\n",
    "y = y[y != 2]\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Escalar los datos para mejorar el rendimiento del SVM\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Entrenar un clasificador SVM\n",
    "svm_clf = SVC(kernel='linear')  # Usar el kernel lineal\n",
    "svm_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluar el clasificador\n",
    "accuracy = svm_clf.score(X_test_scaled, y_test)\n",
    "print(f\"Precisi√≥n del clasificador SVM: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder ejecutar correctamente la clasificaci√≥n necesitamos que la lista **tr_labels** sea una lista de enteros y asi tener solo las clases 0 y 1. La lista de validaci√≥n **tr_val** ya se formateo correctamente a enteros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_labels = list(map(int, tr_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos la liber√≠a **sklearn** para construir la m√°quina de soporte vectorial. \n",
    "\n",
    "`Scikit-learn` (importado generalmente como `sklearn`) es una biblioteca de Python muy popular para machine learning. Ofrece una amplia gama de algoritmos tanto para aprendizaje supervisado (como clasificaci√≥n y regresi√≥n) como no supervisado (como agrupamiento y reducci√≥n de dimensionalidad), junto con herramientas para la selecci√≥n de modelos, preprocesamiento de datos, evaluaci√≥n de modelos y muchas otras utilidades.\n",
    "\n",
    "A continuaci√≥n, te explico brevemente cada uno de los componentes de `scikit-learn` que mencionaste, enfoc√°ndome en c√≥mo se utilizan en el contexto de clasificar una bolsa de palabras:\n",
    "\n",
    "### 1. `svm`\n",
    "\n",
    "El m√≥dulo `svm` de `scikit-learn` proporciona clases para diferentes tipos de M√°quinas de Vectores de Soporte (SVM), que es un conjunto poderoso de algoritmos utilizados para clasificaci√≥n, regresi√≥n y detecci√≥n de outliers. En el contexto de clasificaci√≥n de una bolsa de palabras, podr√≠as usar `SVC` (Support Vector Classification) para clasificar textos en diferentes categor√≠as."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0 0 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0 1 1 0 0 1 0 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# Crear una instancia del clasificador SVM\n",
    "clf = svm.SVC(kernel='linear')  # El kernel puede ser 'linear', 'poly', 'rbf', 'sigmoid', etc.\n",
    "\n",
    "# Entrenar el clasificador con los datos de entrenamiento\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predecir las etiquetas para los datos de prueba\n",
    "y_pred = clf.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. `model_selection.GridSearchCV`\n",
    "\n",
    "`GridSearchCV` es una herramienta que te permite encontrar los mejores par√°metros para tu modelo de forma automatizada. Realiza una b√∫squeda exhaustiva sobre los par√°metros especificados de un modelo para encontrar la combinaci√≥n que da los mejores resultados de acuerdo con una m√©trica de evaluaci√≥n determinada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.001, kernel=linear; total time=   0.0s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definir el espacio de par√°metros para la b√∫squeda\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],  # Regularizaci√≥n\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],  # Par√°metro para el kernel 'rbf'\n",
    "    'kernel': ['rbf', 'linear']  # Tipo de kernel\n",
    "}\n",
    "\n",
    "# Crear una instancia de GridSearchCV\n",
    "grid_search = GridSearchCV(svm.SVC(), param_grid, refit=True, verbose=2)\n",
    "\n",
    "# Ejecutar la b√∫squeda en los datos de entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtener el mejor clasificador\n",
    "best_clf = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. `metrics`\n",
    "\n",
    "El m√≥dulo `metrics` incluye una variedad de funciones de puntuaci√≥n, m√©tricas de p√©rdida y utilidades para medir el rendimiento de tu modelo. Estas m√©tricas son cruciales para evaluar qu√© tan bien tu modelo est√° clasificando los datos.\n",
    "\n",
    "- **`accuracy_score`**: Mide la precisi√≥n general del modelo, es decir, la proporci√≥n de predicciones correctas.\n",
    "- **`confusion_matrix`**: Proporciona una matriz que muestra las clasificaciones correctas e incorrectas entre las clases reales y las predichas.\n",
    "- **`f1_score`**: Es una medida que combina la precisi√≥n y la exhaustividad (recall) para dar una sola puntuaci√≥n que balancea ambas.\n",
    "- **`precision_recall_fscore_support`**: Calcula la precisi√≥n, la exhaustividad, el puntaje F1 y el soporte para cada clase.\n",
    "- **`roc_auc_score`**: Mide el √°rea bajo la curva ROC (Receiver Operating Characteristic), que es √∫til para evaluar la calidad de las predicciones de un clasificador en t√©rminos de su capacidad para distinguir entre clases.\n",
    "\n",
    "Ejemplo de uso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisi√≥n: 1.0\n",
      "Matriz de Confusi√≥n:\n",
      "[[17  0]\n",
      " [ 0 13]]\n",
      "F1 Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "\n",
    "# Precisi√≥n\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Matriz de confusi√≥n\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_test, y_pred, average='binary')  # 'average' puede ser 'micro', 'macro', 'weighted', dependiendo del problema\n",
    "\n",
    "print(f\"Precisi√≥n: {accuracy}\")\n",
    "print(f\"Matriz de Confusi√≥n:\\n{conf_matrix}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada una de estas funciones y clases de `scikit-learn` es muy poderosa y puede ser personalizada de muchas maneras para adaptarse a las necesidades espec√≠ficas de tu problema de clasificaci√≥n. Es importante experimentar con diferentes configuraciones y evaluar tu modelo con varias m√©tricas para obtener una comprensi√≥n completa de su rendimiento.\n",
    "\n",
    "Si ahora aplicamos esto a nuestro modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_recall_fscore_support, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queremos ajustar el par√°metro $c$ de complejidad. Utilizamos GridSearchCV para esto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83       418\n",
      "           1       1.00      0.01      0.01       169\n",
      "\n",
      "    accuracy                           0.71       587\n",
      "   macro avg       0.86      0.50      0.42       587\n",
      "weighted avg       0.80      0.71      0.60       587\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guillermo_sego/anaconda3/envs/PLN/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "parameters = {'C': [0.05, .12, .25, .5, 1, 2, 4]}\n",
    "\n",
    "# M√°quina de soporte vectorial\n",
    "srv = svm.LinearSVC(class_weight='balanced')\n",
    "grid = GridSearchCV(estimator=srv, param_grid=parameters, n_jobs = 8, scoring = \"f1_macro\",cv = 5)\n",
    "\n",
    "# Hacer la b√∫squeda sobre la bolsa de palabras\n",
    "grid.fit(BOW_tr, tr_labels)\n",
    "\n",
    "y_pred = grid.predict(BOW_val)\n",
    "\n",
    "p, r, f, _ = precision_recall_fscore_support(val_labels, y_pred, average=\"macro\", pos_label = 1)\n",
    "print(metrics.classification_report(val_labels, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este informe de clasificaci√≥n muestra las m√©tricas de rendimiento de un clasificador SVM que se ha entrenado y probado en un conjunto de datos de tweets, donde se intenta predecir si un tweet es agresivo (clase 1) o no agresivo (clase 0). A continuaci√≥n, interpretaci√≥n:\n",
    "\n",
    "### Por Clase:\n",
    "\n",
    "- **Clase 0 (No agresivo)**:\n",
    "  - **Precision**: La precisi√≥n es del 71%, lo que significa que, de todas las instancias clasificadas como no agresivas por el modelo, el 71% realmente eran no agresivas.\n",
    "  - **Recall**: El recall es del 100%, indicando que el modelo identific√≥ correctamente el 100% de todos los tweets no agresivos en el conjunto de datos.\n",
    "  - **F1-Score**: El F1-score, que combina precisi√≥n y recall en una sola m√©trica, es del 83%. Un valor alto sugiere un buen equilibrio entre precisi√≥n y recall.\n",
    "\n",
    "- **Clase 1 (Agresivo)**:\n",
    "  - **Precision**: La precisi√≥n es del 100%, lo que significa que todos los tweets que el modelo identific√≥ como agresivos eran realmente agresivos. Sin embargo, esta alta precisi√≥n puede ser enga√±osa debido al muy bajo recall.\n",
    "  - **Recall**: El recall es extremadamente bajo, solo del 1%, lo que indica que el modelo apenas identific√≥ correctamente los tweets agresivos presentes en el conjunto de datos.\n",
    "  - **F1-Score**: El F1-score es del 1%, lo cual es muy bajo y refleja el pobre rendimiento del modelo en la detecci√≥n de tweets agresivos debido al bajo recall.\n",
    "\n",
    "### Promedios:\n",
    "\n",
    "- **Accuracy**: La precisi√≥n general del modelo es del 71%, lo que significa que el 71% de todas las predicciones realizadas por el modelo fueron correctas. Sin embargo, esta m√©trica puede ser enga√±osa en conjuntos de datos desequilibrados donde una clase es mucho m√°s prevalente.\n",
    "\n",
    "- **Macro Avg**:\n",
    "  - La precisi√≥n macro promedio es del 86%, y el recall macro promedio es del 50%, lo que resulta en un F1-score macro promedio del 42%. El promedio macro trata a todas las clases por igual, sin tener en cuenta el desbalance entre clases. Aunque la precisi√≥n macro parece alta, el recall bajo para la clase agresiva reduce significativamente el F1-score macro.\n",
    "\n",
    "- **Weighted Avg**:\n",
    "  - La precisi√≥n ponderada promedio es del 80%, y el recall ponderada promedio (igual a la precisi√≥n general) es del 71%, con un F1-score ponderado promedio del 60%. Estos promedios ponderados tienen en cuenta el soporte (n√∫mero de instancias) de cada clase, por lo que dan m√°s peso a la clase m√°s prevalente (no agresiva en este caso).\n",
    "\n",
    "### Interpretaci√≥n y Consideraciones:\n",
    "\n",
    "El modelo tiene un excelente rendimiento para identificar tweets no agresivos, pero lucha significativamente para identificar tweets agresivos, como lo demuestra el recall extremadamente bajo para la clase 1. Esto podr√≠a deberse a varias razones, como un desequilibrio en el conjunto de datos (mucho m√°s tweets no agresivos que agresivos), caracter√≠sticas no informativas para la clase agresiva, o la necesidad de ajustar mejor los par√°metros del modelo.\n",
    "\n",
    "Dado el contexto de la clasificaci√≥n de agresividad en tweets, es crucial mejorar el recall para la clase agresiva sin sacrificar demasiado la precisi√≥n, ya que identificar correctamente los tweets agresivos es vital para la aplicaci√≥n pr√°ctica de este modelo.\n",
    "\n",
    "Para mejorar el rendimiento en la clase agresiva, podr√≠as considerar las siguientes estrategias:\n",
    "- **Rebalanceo de clases**: Utilizar t√©cnicas como sobremuestreo de la clase minoritaria o submuestreo de la clase mayoritaria.\n",
    "- **Ingenier√≠a de caracter√≠sticas**: Desarrollar o seleccionar caracter√≠sticas m√°s informativas espec√≠ficas para identificar la agresividad.\n",
    "- **Ajuste de par√°metros**: Continuar ajustando los par√°metros del modelo SVM, posiblemente explorando m√°s all√° de los valores de `C` proporcionados.\n",
    "- **Evaluaci√≥n con otras m√©tricas**: Centrarse en m√©tricas que sean m√°s informativas para conjuntos de datos desequilibrados, como el √°rea bajo la curva ROC (AUC-ROC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora vemos la lista de los ejemplos incorrectos\n",
    "\n",
    "incorrect = []\n",
    "\n",
    "for e in zip(val_labels, y_pred, range(len(val_labels))):\n",
    "    if e[0] != e[1]:\n",
    "        incorrect += [e[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto:  Al perro que se te acerque le parto su madre a si de facil\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  Por un mega-error escuch√© parte de una canci√≥n de banda y decia \"Demosle vuelo a la hilacha\" Que putas madres üòÇüòÇ #PenaAjena\n",
      "Truth:  0\n",
      "Pred:  1\n",
      "Texto:  @USUARIO Q gusto m daria q Peru elimine a la Argentina y la concha d la perra mas puta d Argentina la madre d @USUARIO\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  @USUARIO Ya m tienen hasta la madre esos maes\n",
      "Truth:  0\n",
      "Pred:  1\n",
      "Texto:  Me caga esa gente a la que le mientas la madre y ni siquiera tienen la decencia de contestar. Putos, les dicen.\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  @USUARIO @USUARIO Lo peor es q uds siguen hablando de enga√±ar al pueblo\" hijos de su puta madre, pinches pol√≠ticos de mierda\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  Pero un d√≠a te voy a tapar el culo mientras te estoy lamiendo la pantunfla a ver si te da una embolia, hija de tu puta madre\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  #PorMiCamisetaYo mando a chingar a su reputisima madre al Am√©rica,  Televisa y Tvazteca chinguen a su madre mil veces!\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  Por est√° madre me agarr√© a vergazos con el de la combi y no le pagu√©, el puto dec√≠a que ya no valen.\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  Por mi los dos chinguen a su madre aqu√≠ y en persona par de putos\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  Pol√≠ticos pseudoaficiomados que s√≥lo en finales hablan de beisbol pueden ir mucho a chingar a su madre. Y peor cuando opinan.\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  Chingas a tu madre vulgar ladr√≥n y junto a ti todos los que te aplauden.\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  Ya nomas sienten que lo tienen asegurado a uno y se empiezan a tardar en Whatsapp las hijas de sus putas madres.\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  chinguen su madre putos chilenos de mierda, #M√©xico en el mundial y tu pa√≠s basura lo ver√° por TV jajaja üòÑ\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  @USUARIO @USUARIO @USUARIO Ese conchadesumadre del Yerko, que ni siquiera le alcanza pa maric√≥n, porque hay que ser hombre antes y a ese le alcanza pa la mitad apenas\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  Verga pendejo y eso t lo platico tu madre verdad jajajaja est√∫pido joto de closet\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  Ah qu√© poca madre aretes y pesta√±as al perro, que las usen sus pinches due√±as pars ver si se les quita lo ignorante. <URL>\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  @USUARIO Presidente Trump, chingas a tu madre\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  @USUARIO Anda a dialogar con tu madre que posiblemente es la √∫nica que le queda un poco de paciencia diputado de mierd@ Renuncia hdp\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  Le cambiaron al canal donde estaba el partido, chinguen a su madre  #MexicanDesmotherPalMundial\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  Y chingas a tu puta madre, si te llego a encontrar maric√≥n de mierda no vas a valer ni 10 centavos y me vale verga si tienes familia puto.\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  Acosaron a la amiga de mi novio en el cami√≥n üò§ que vayan a acosar a sus putas madres hijos de la chingada.\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  @USUARIO @USUARIO @USUARIO @USUARIO @USUARIO Poca madre tienen enrique dice el PRI es pura transparencia puro robar a lo descarado y la gente de la cierra que se chinguen bola de ratas\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  @USUARIO Muchas gracias Q:.H:., p√°sale t√∫ tambi√©n a chingar a tu madre, T.:A.:F:. #Mi√©rcolesDeMentadas\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  @USUARIO @USUARIO üòÇüòÇüòÇ...este hijo de su asesina madre est√° idiota, enfermo, mariguano, alguien que lo bloquee en Twitter  por favor..\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  @USUARIO No tienen abuela madre verg√ºenza....\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  El Gobierno Federal acaba de inaugurar una nueva ruta para que vayas y chingues toda tu reput√≠sima madre\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  Ticos putos y llorones jajajaja les sigue llorando que M√©xico siga siendo su padre, chinguen a su madre\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  Yo aqu√≠ pudiendo quererte bonito y t√∫ haya quej√°ndote de que nadie te quiere hijo de tu madre\n",
      "Truth:  1\n",
      "Pred:  0\n",
      "Texto:  Lo √∫nico bueno de regresar con tu ex novia es que ya sabes de que croquetas le gustan a la hija de su perra madre.\n",
      "Truth:  1\n",
      "Pred:  0\n"
     ]
    }
   ],
   "source": [
    "for e in incorrect:\n",
    "    case = e\n",
    "\n",
    "    if \"madre\" in val_text[case].strip():\n",
    "        print(\"Texto: \", val_text[case].strip())\n",
    "        print(\"Truth: \", val_labels[case])\n",
    "        print(\"Pred: \", y_pred[case])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PLN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
