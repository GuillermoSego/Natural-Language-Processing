{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto final. Natural Languaje Processing\n",
    "### Demo. Modelo BERT para finetuning\n",
    "\n",
    "Guillermo Segura Gómez\n",
    "\n",
    "#### ¿Qué es un modelo BERT?\n",
    "\n",
    "**BERT (Bidirectional Encoder Representations from Transformers)** es un modelo de lenguaje desarrollado por Google. Es uno de los modelos más avanzados en procesamiento de lenguaje natural (NLP). BERT es un transformador bidireccional, lo que significa que tiene en cuenta el contexto de las palabras tanto a la izquierda como a la derecha de una palabra en una oración.\n",
    "\n",
    "##### Características Clave de BERT:\n",
    "1. **Bidireccionalidad**: Analiza el contexto de una palabra en ambos sentidos (izquierda y derecha).\n",
    "2. **Pre-entrenamiento y Fine-tuning**: BERT se pre-entrena en grandes cantidades de texto sin etiquetar (como Wikipedia) y luego se puede ajustar finamente (fine-tuning) para tareas específicas.\n",
    "3. **Transformadores**: Utiliza la arquitectura de transformadores, que es altamente eficiente para capturar dependencias a largo plazo en texto.\n",
    "\n",
    "##### Aplicaciones Comunes de BERT:\n",
    "1. **Clasificación de Texto**: Clasificación de sentimientos, clasificación de spam, etc.\n",
    "2. **Reconocimiento de Entidades Nombradas (NER)**: Identificación de nombres de personas, organizaciones, ubicaciones, etc.\n",
    "3. **Respuesta a Preguntas**: Sistemas de preguntas y respuestas donde el modelo encuentra la respuesta en un párrafo de texto.\n",
    "4. **Traducción de Idiomas**: Traducción automática de texto de un idioma a otro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device=cpu\n"
     ]
    }
   ],
   "source": [
    "# Librerias\n",
    "from transformers import TrainingArguments, Trainer, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import json\n",
    "import argparse\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import random\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "# Configuración del dispositivo (CPU o GPU)\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\"\n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "print(f\"Using device={DEVICE}\")\n",
    "\n",
    "# Función para mover los datos a la GPU si está disponible\n",
    "def to_cuda(var):\n",
    "    if DEVICE == \"cuda\":\n",
    "        return var.cuda()\n",
    "    return var\n",
    "\n",
    "# Definición de métricas de evaluación\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, zero_division=0.0, average=\"binary\", pos_label=1)\n",
    "    tn, fp, fn, tp = confusion_matrix(labels, preds).ravel()\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'tp': tp,\n",
    "        'tn': tn,\n",
    "        'fp': fp,\n",
    "        'fn': fn\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. **Arquitectura de BERT**\n",
    "\n",
    "BERT consta de una serie de capas de atención (self atention layers) que procesan el texto de entrada para producir representaciones contextuales de cada token.\n",
    "\n",
    "##### Componentes Principales de BERT:\n",
    "\n",
    "1. **Tokenización**: BERT utiliza un tokenizador para dividir el texto en tokens (subpalabras) y agregar tokens especiales como `[CLS]` (inicio de secuencia) y `[SEP]` (separador de secuencias).\n",
    "2. **Embeddings**: Los tokens son convertidos a vectores de embeddings que capturan información semántica.\n",
    "3. **Capas de Transformadores**: Una serie de capas de atención bidireccional que procesan los embeddings para generar representaciones contextuales de cada token.\n",
    "4. **Salida**: La salida de la última capa de BERT es una secuencia de vectores que representan cada token en su contexto.\n",
    "\n",
    "#### 2. **Proceso de Fine-Tuning**\n",
    "\n",
    "El fine-tuning es el proceso de ajustar un modelo preentrenado a una tarea específica utilizando datos etiquetados. En este caso clasificación de texto, esto implica ajustar los pesos del modelo utilizando un conjunto de datos donde cada texto tiene una etiqueta correspondiente.\n",
    "\n",
    "##### Componentes del Fine-Tuning en BERT:\n",
    "\n",
    "1. **Capa de Clasificación**: Se agrega una capa de clasificación al final del modelo BERT. Esta capa toma la representación del token `[CLS]` y la usa para predecir la etiqueta de la secuencia de entrada.\n",
    "2. **Entrenamiento**: El modelo se entrena utilizando los datos etiquetados. Durante el entrenamiento, se ajustan todos los pesos del modelo BERT (o solo algunos, dependiendo de la configuración).\n",
    "\n",
    "#### 3. **Etiquetas y Salidas en BERT**\n",
    "\n",
    "##### 3.1 Etiquetas en Datos de Entrenamiento\n",
    "\n",
    "Las etiquetas en los datos de entrenamiento son las clasificaciones asignadas a cada secuencia de entrada. \n",
    "\n",
    "##### 3.2 Salidas del Modelo\n",
    "\n",
    "La salida de BERT para una tarea de clasificación es un vector de logits que se convierte en una probabilidad para cada clase mediante una función softmax. La clase con la mayor probabilidad se selecciona como la predicción del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para manejar los datos de entrada\n",
    "class SentimentDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor([self.labels[idx]])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Función para simulación de datos mal etiquetados\n",
    "def mislabel_data(data, percent):\n",
    "    print(f\"WARNING: Mislabeling {percent}% of data ({int(len(data)*(percent/100))} lines)!\")\n",
    "    indices_to_change = random.sample(range(len(data)), int(len(data)*(percent/100)))\n",
    "    for idx in indices_to_change:\n",
    "        if data[idx][\"label\"] == 0:\n",
    "            data[idx][\"label\"] = 1  \n",
    "        else:\n",
    "            data[idx][\"label\"] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para cargar los datos de un archivo y tokenizarlos con el tokenizador de BERT\n",
    "def load_dataset_from_file(fpath, tokenizer, cfg):\n",
    "    with open(fpath, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "    if cfg[\"reduce_lines_for_testing\"]:\n",
    "        data = data[:100]\n",
    "    encodings = tokenizer([d[\"txt\"] for d in data], truncation=True, padding=True, max_length=cfg[\"max_len\"])\n",
    "    return data, SentimentDataset(encodings=encodings, labels=[d[\"label\"] for d in data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función principal\n",
    "def main(cfg):\n",
    "    # Definición de parámetros por defecto\n",
    "    default_params = {\n",
    "        \"num_epochs\": 5,\n",
    "        \"batch_size\": 16,\n",
    "        \"max_len\": 512,\n",
    "        \"model_save_location\": None,\n",
    "        \"freeze_encoder\": False,\n",
    "        \"log_test_outputs\": False,\n",
    "        \"train_fpath\": None,\n",
    "        \"dev_fpath\": None,\n",
    "        \"test_fpath\": None,\n",
    "        \"inference_fpath\": None,\n",
    "        \"inference_results_savepath\": None,\n",
    "        \"final_test_fpath\": None,\n",
    "    }\n",
    "    # Sobrescribir los parámetros por defecto con los valores del archivo de configuración\n",
    "    for key in default_params:\n",
    "        cfg[key] = cfg.get(key, default_params[key])\n",
    "\n",
    "    # Cargar el tokenizer y el modelo preentrenado de BERT\n",
    "    tokenizer = AutoTokenizer.from_pretrained(cfg[\"model_name\"])\n",
    "    model = to_cuda(AutoModelForSequenceClassification.from_pretrained(cfg[\"model_name\"], num_labels=2))\n",
    "\n",
    "\n",
    "    # Cargar los datos de entrenamiento, validación y prueba\n",
    "    if cfg[\"train_fpath\"] is not None:\n",
    "        # Advertencia si se está reduciendo el tamaño de los datos para pruebas\n",
    "        if cfg[\"reduce_lines_for_testing\"]:\n",
    "            print(\"WARNING: Keeping only 100 sentences for test and train for testing!\")\n",
    "\n",
    "        # Cargar y tokenizar los datos de entrenamiento\n",
    "        train_data, train_dataset = load_dataset_from_file(cfg[\"train_fpath\"], tokenizer, cfg)\n",
    "\n",
    "        eval_datasets = {}\n",
    "\n",
    "        # Cargar y tokenizar los datos de validación si están disponibles\n",
    "        if cfg[\"dev_fpath\"] is not None:\n",
    "            dev_data, eval_datasets[\"dev\"] = load_dataset_from_file(cfg[\"dev_fpath\"], tokenizer, cfg)\n",
    "        \n",
    "        # Cargar y tokenizar los datos de prueba si están disponibles\n",
    "        if cfg[\"test_fpath\"] is not None:\n",
    "            test_data, eval_datasets[\"test\"] = load_dataset_from_file(cfg[\"test_fpath\"], tokenizer, cfg)\n",
    "\n",
    "        final_test_dataset = None\n",
    "        # Asignar los datos de prueba finales\n",
    "        if cfg[\"final_test_fpath\"] is None and cfg[\"test_fpath\"] is not None:\n",
    "            final_test_data = test_data\n",
    "            final_test_dataset = eval_datasets[\"test\"]\n",
    "        elif cfg[\"final_test_fpath\"] is not None:\n",
    "            final_test_data, final_test_dataset = load_dataset_from_file(cfg[\"final_test_fpath\"], tokenizer, cfg)\n",
    "\n",
    "        # Simular datos mal etiquetados si se especifica\n",
    "        if int(cfg[\"mislabel_percent\"]) != 0:\n",
    "            mislabel_data(train_data, cfg[\"mislabel_percent\"])\n",
    "\n",
    "        # Imprimir el número de muestras cargadas para cada conjunto de datos\n",
    "        print(f\"Number of train samples loaded: {len(train_data)}\")\n",
    "        if cfg[\"dev_fpath\"] is not None:\n",
    "            print(f\"Number of dev samples loaded: {len(eval_datasets['dev'])}\")\n",
    "        if cfg[\"test_fpath\"] is not None:\n",
    "            print(f\"Number of test samples loaded: {len(eval_datasets['test'])}\")\n",
    "        if cfg[\"final_test_fpath\"] is not None:\n",
    "            print(f\"Number of final test samples loaded: {len(final_test_dataset)}\")\n",
    "\n",
    "        # Configuración estrategía de evaluación y congelación de parámetros del modelo\n",
    "\n",
    "            # Definir la estrategia de evaluación\n",
    "        if cfg[\"dev_fpath\"] or cfg[\"test_fpath\"]:\n",
    "            evaluation_strategy = \"steps\"\n",
    "        else:\n",
    "            evaluation_strategy = \"no\"\n",
    "        print(f\"Using evaluation strategy {evaluation_strategy}\")\n",
    "\n",
    "        # Congelar los parámetros del encoder si se especifica\n",
    "        if cfg[\"freeze_encoder\"]:\n",
    "            for name, param in model.named_parameters():\n",
    "                if \"embedding\" in name or \"encoder\" in name:\n",
    "                    param.requires_grad = False\n",
    "\n",
    "        # Configuración de argumentos del entrenamiento\n",
    "\n",
    "            # Configuración de los pasos de calentamiento y registro\n",
    "        if cfg[\"reduce_lines_for_testing\"]:\n",
    "            warmup_steps = 1\n",
    "            logging_steps = 1\n",
    "        else:\n",
    "            warmup_steps = int(1000/cfg[\"batch_size\"])\n",
    "            logging_steps = int((cfg[\"num_epochs\"]*len(train_dataset))/(cfg[\"batch_size\"]*30))\n",
    "            print(f\"logging_steps: {logging_steps}\")\n",
    "\n",
    "        # Definición de argumentos de entrenamiento\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir='./results',         \n",
    "            num_train_epochs=cfg[\"num_epochs\"],             \n",
    "            per_device_train_batch_size=cfg[\"batch_size\"], \n",
    "            per_device_eval_batch_size=cfg[\"batch_size\"], \n",
    "            warmup_steps=warmup_steps,                \n",
    "            weight_decay=0.01,            \n",
    "            logging_dir='./logs',           \n",
    "            load_best_model_at_end=False,\n",
    "            learning_rate=cfg[\"lr\"],\n",
    "            logging_steps=logging_steps,\n",
    "            save_strategy='no',\n",
    "            evaluation_strategy=evaluation_strategy,    \n",
    "            report_to=\"none\",\n",
    "            seed=int(datetime.now().timestamp())\n",
    "        )\n",
    "\n",
    "    # Entrenamiento del modelo y evaluación\n",
    "\n",
    "        # Inicialización del entrenador\n",
    "        trainer = Trainer(\n",
    "            model=model,                         \n",
    "            args=training_args,                  \n",
    "            train_dataset=train_dataset,         \n",
    "            eval_dataset=eval_datasets,          \n",
    "            compute_metrics=compute_metrics,     \n",
    "        )\n",
    "\n",
    "        # Entrenar el modelo\n",
    "        trainer.train()\n",
    "\n",
    "        # Evaluar el modelo en el conjunto de validación si está disponible\n",
    "        if \"dev\" in eval_datasets:\n",
    "            val_predict_results = trainer.predict(\n",
    "                test_dataset=eval_datasets[\"dev\"],\n",
    "            )\n",
    "\n",
    "        # Evaluar el modelo en el conjunto de prueba final si está disponible\n",
    "        if final_test_dataset is not None:\n",
    "            test_predict_results = trainer.predict(\n",
    "                test_dataset=final_test_dataset,\n",
    "            )\n",
    "            test_metrics = compute_metrics(test_predict_results)\n",
    "            for key, val in test_metrics.items():\n",
    "                print(f\"final_test/{key}: {val}\")\n",
    "\n",
    "            # Registrar las salidas de prueba si se especifica\n",
    "            if cfg[\"log_test_outputs\"]:\n",
    "                print(f\"Logging all test outputs...\")\n",
    "                prediction_results = test_predict_results._asdict()\n",
    "                with open(os.path.join(cfg[\"model_save_location\"], 'test_outputs.txt'), 'w') as f:\n",
    "                    f.write(\"\\n\".join([str(np.argmax(x)) for x in prediction_results[\"predictions\"]]))\n",
    "\n",
    "        # Guardar el modelo y el tokenizer si se especifica una ubicación para guardar\n",
    "        if cfg[\"model_save_location\"] is not None:\n",
    "            dirname = cfg[\"model_save_location\"]\n",
    "            if dirname is not None:\n",
    "                print(f\"Saving model to {dirname}\")\n",
    "                if not os.path.exists(dirname):\n",
    "                    os.makedirs(dirname)\n",
    "                trainer.save_model(dirname)\n",
    "                tokenizer.save_pretrained(dirname)\n",
    "\n",
    "    # Función para inferir con un modelo entrenado\n",
    "    # Modo de inferencia\n",
    "    elif cfg[\"inference_fpath\"] is not None:\n",
    "        # Cargar los datos de inferencia\n",
    "        with open(cfg[\"inference_fpath\"], \"r\") as file:\n",
    "            data = json.load(file)\n",
    "        if cfg[\"reduce_lines_for_testing\"]:\n",
    "            data = data[:100]\n",
    "\n",
    "        results = []\n",
    "        # Realizar inferencia en lotes\n",
    "        for i in tqdm(range(0, len(data), cfg[\"batch_size\"]), desc=\"Inference\"):\n",
    "            batch = data[i:i+cfg[\"batch_size\"]]\n",
    "            encodings = tokenizer(batch, truncation=True, padding=True, max_length=cfg[\"max_len\"], return_tensors=\"pt\")\n",
    "            input_ids = to_cuda(encodings['input_ids'])\n",
    "            attention_mask = to_cuda(encodings['attention_mask'])\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_ids, attention_mask=attention_mask).logits\n",
    "\n",
    "            results += torch.max(logits, dim=-1).indices.cpu().numpy().tolist()\n",
    "\n",
    "        # Guardar los resultados de la inferencia\n",
    "        output_fname = f'{os.path.basename(cfg[\"inference_fpath\"]).split(\".\")[0]}_labels_{os.path.basename(os.path.normpath(cfg[\"model_name\"]))}.json'\n",
    "        with open(os.path.join(cfg[\"inference_results_savepath\"], output_fname), 'w') as outfile:\n",
    "            json.dump(results, outfile, indent=3)\n",
    "\n",
    "    else:\n",
    "        print(\"Either train_fpath or inference_fpath needs to be given. Doing nothing...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: Bert finetuning [-h] -c CONFIG_PATH\n",
      "Bert finetuning: error: the following arguments are required: -c/--config_path\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(prog='Bert finetuning', description='This program finetunes a BERT model')\n",
    "    parser.add_argument('-c', '--config_path', required=True)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    cfg, _ = parse(args.config_path)\n",
    "    for c in cfg:\n",
    "        random.seed(int(datetime.now().timestamp()))\n",
    "        torch.manual_seed(int(datetime.now().timestamp()))\n",
    "        np.random.seed(int(datetime.now().timestamp()))\n",
    "        main(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PLN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
